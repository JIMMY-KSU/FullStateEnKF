{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import sympy as sym\n",
    "from scipy.integrate import ode\n",
    "from scipy.io import loadmat\n",
    "import scipy.io\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import copy\n",
    "import filter_functions\n",
    "from sympy.utilities.lambdify import lambdify\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.debugger import Tracer\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 6.0)\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14\n",
    "np.set_printoptions(precision=15)\n",
    "sym.init_printing()\n",
    "from IPython.display import display\n",
    "\n",
    "#MSIS: https://github.com/DeepHorizons/Python-NRLMSISE-00\n",
    "#import time\n",
    "from nrlmsise_00_header import *\n",
    "from nrlmsise_00 import *\n",
    "#SUBROUTINE GTD7D -- d[5] is the \"effective total mass density\n",
    "#for drag\" and is the sum of the mass densities of all species\n",
    "#in this model, INCLUDING anomalous oxygen.\n",
    "\n",
    "#define constants\n",
    "r_earth_const = 6378136.3 * 1e-3 #km\n",
    "omega_const = 7.2921158553e-5 #rad/s, angular velocity of earth\n",
    "J_2_const = .00108262617385222\n",
    "J_3_const = -.00000253241051856772\n",
    "mu_earth = 3.986004415e14 * 1e-9 #km^3/s^2\n",
    "\n",
    "\n",
    "#Drag:\n",
    "A_const = 0.9551567 * 1e-6 #km^2; cross-sectional area of satellite\n",
    "m_const = 10 #kg; mass of satellite\n",
    "C_D_const = 2.0\n",
    "theta_dot_const = 7.2921158553e-5 #rad/sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(407, 5)\n",
      "(407, 6)\n",
      "784.0\n",
      "7.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntruth_xyz = truth_xyz[0::20]\\nmeasurement_array = measurement_array[0::20]\\ntrue_density_array = true_density_array[0::20]\\nlat_lst_meas_array = lat_lst_meas_array[0::20]\\nprint(measurement_array[50,0]/(60))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_of_X_ensembles = 450\n",
    "\n",
    "meas_type = 3\n",
    "\n",
    "if meas_type == 1:\n",
    "    meas_file = open('Data Files/meas_range_rangeRate.pkl', 'rb')\n",
    "elif meas_type == 2:\n",
    "    meas_file = open('Data Files/meas_az_el.pkl', 'rb')\n",
    "elif meas_type == 3:\n",
    "    meas_file = open('Data Files/meas_az_el_range_90RAAN.pkl', 'rb') #_10s_all_3stat.pkl\n",
    "    \n",
    "    \n",
    "    \n",
    "#Date of Simulation Details:\n",
    "#June 24th, 2017 at 6am (this is the date & time at the beginning of the simulation/orbit)\n",
    "year_init = 2017\n",
    "month_init = 6\n",
    "day_of_month_init = 24\n",
    "day_of_year_init = 175\n",
    "hour_init = 6\n",
    "boulder_UT_offset = 6 #Boulder time + 6 hours = UT time\n",
    "hour_init_UT = hour_init + boulder_UT_offset\n",
    "    \n",
    "    \n",
    "\n",
    "#Canbera Station (DSS 34)\n",
    "lat_dss34 = math.radians(-35.398333)\n",
    "lon_dss34 = math.radians(148.981944)\n",
    "alt_dss34 = 691.75 * 1e-3 #km\n",
    "\n",
    "r_ecef_dss34 = filter_functions.topo2ecef(lat_dss34, lon_dss34, alt_dss34, r_earth_const)\n",
    "#print(r_ecef_dss34)\n",
    "\n",
    "#Madrid Station (DSS 65) -- correct position of Madrid Station\n",
    "lat_dss65 = math.radians(40.427222)\n",
    "lon_dss65 = math.radians(355.749444)\n",
    "alt_dss65 = 834.539 * 1e-3 #km\n",
    "\n",
    "r_ecef_dss65 = filter_functions.topo2ecef(lat_dss65, lon_dss65, alt_dss65, r_earth_const)\n",
    "#print(r_ecef_dss65)\n",
    "\n",
    "#Goldstone Station (DSS 13) \n",
    "lat_dss13 = math.radians(35.247164)\n",
    "lon_dss13 = math.radians(200.205)\n",
    "alt_dss13 = 1071.14904 * 1e-3 #km\n",
    "\n",
    "r_ecef_dss13 = filter_functions.topo2ecef(lat_dss13, lon_dss13, alt_dss13, r_earth_const)\n",
    "#print(r_ecef_dss13)\n",
    "\n",
    "#Diego Garcia, British Indian Ocean Territory 7.41173°S 72.45222°E., Space Fence (Dedicated Sensor\n",
    "lat_diego = math.radians(-7.41173)\n",
    "lon_diego = math.radians(72.45222)\n",
    "alt_diego = 0 * 1e-3 #km, \"sea level\"\n",
    "\n",
    "r_ecef_diego = filter_functions.topo2ecef(lat_diego, lon_diego, alt_diego, r_earth_const)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# read python dict containing measurements\n",
    "mydict2 = pickle.load(meas_file)\n",
    "meas_file.close()\n",
    "measurement_array = mydict2['measurement_array']\n",
    "truth_xyz = mydict2['truth_pos_vel']\n",
    "true_density_array = mydict2['true_density']*1e9\n",
    "lat_lst_meas_array = mydict2['lat_lst_array']\n",
    "print(np.shape(measurement_array))\n",
    "print(np.shape(truth_xyz))\n",
    "\n",
    "#convert to km\n",
    "truth_xyz = truth_xyz * 1e-3\n",
    "measurement_array[:, -1] = measurement_array[:, -1] * 1e-3\n",
    "print(measurement_array[200,0]/(60))\n",
    "print(measurement_array[150,0]/(60)/90)\n",
    "\n",
    "\n",
    "\n",
    "#sample measurements so only using every nth measurement\n",
    "\"\"\"\n",
    "truth_xyz = truth_xyz[0::20]\n",
    "measurement_array = measurement_array[0::20]\n",
    "true_density_array = true_density_array[0::20]\n",
    "lat_lst_meas_array = lat_lst_meas_array[0::20]\n",
    "print(measurement_array[50,0]/(60))\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Vector of State/density Ensembles: (450, 37, 73)\n",
      "0.000479211906198\n",
      "0.000487590126762\n"
     ]
    }
   ],
   "source": [
    "#read in files necessary for ensemble & density est. portion\n",
    "\n",
    "\n",
    "# read python dict containing densities\n",
    "ensemble_file = open('Data Files/ensemble_density_grids.pkl', 'rb')\n",
    "mydict2 = pickle.load(ensemble_file)\n",
    "ensemble_file.close()\n",
    "\n",
    "#shape: ensembles (# of combos) by lat by lon\n",
    "ensembles_of_density_grid = mydict2['ensemble_of_density_grids'] \n",
    "print('Shape of Vector of State/density Ensembles:', np.shape(ensembles_of_density_grid))\n",
    "(num_of_ensembles, num_of_lat, num_of_lon) = np.shape(ensembles_of_density_grid)\n",
    "\n",
    "#convert from kg/m**3 to kg/km**3 -> 1/(1e-3)**3 = 1/(1e-9) = 1e9\n",
    "ensembles_of_density_grid = ensembles_of_density_grid * 1e9\n",
    "\n",
    "latitude_grid = mydict2['latitudes'] \n",
    "longitude_grid = mydict2['longitudes'] \n",
    "lat_res = latitude_grid[1] - latitude_grid[0] #spacing between each latitude \"tick\"\n",
    "lon_res = longitude_grid[1] - longitude_grid[0] #spacing between each longitude \"tick\"\n",
    "\n",
    "\n",
    "\n",
    "#add noise w/ standard deviation = 1e-4 (used as initialization of density covariance, as well)\n",
    "\n",
    "print(np.sum(ensembles_of_density_grid[:, 0, 0])/num_of_ensembles)\n",
    "ensemble_noise = np.random.randn(num_of_ensembles, num_of_lat, num_of_lon) * 1e-4#1e-9 #1e-4****\n",
    "ensembles_of_density_grid = ensembles_of_density_grid + ensemble_noise\n",
    "print(np.sum(ensembles_of_density_grid[:, 0, 0])/num_of_ensembles) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Propogate reference trajectory and S.T.M.\n",
    "def orbitpropogator_EnKF(t, X_vector, density):\n",
    "    \n",
    "    ensemble_member = X_vector\n",
    "\n",
    "    #find X acceleration via the F(X) lambdified equation\n",
    "    state_acc = X_dot_sol_fcn(ensemble_member[0], ensemble_member[1], ensemble_member[2], \\\n",
    "                                  ensemble_member[3], ensemble_member[4], ensemble_member[5], density)\n",
    "        \n",
    "    dx = state_acc.flatten()\n",
    "    return dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#EnKF specific functionality\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def gen_ensemble(X_0, Bsqrt_cov, ensemble_size):\n",
    "    \n",
    "    X_0 = X_0.reshape(len(X_0), 1)\n",
    "    \n",
    "    ensemble = np.zeros((len(X_0), ensemble_size))\n",
    "    \n",
    "    for ii in range(ensemble_size):\n",
    "        \n",
    "        member = X_0 + np.dot(Bsqrt_cov, np.random.randn(len(X_0), 1))\n",
    "\n",
    "        ensemble[:, ii] = member.reshape(len(X_0))\n",
    "    \n",
    "    return ensemble\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#two body motion force\n",
    "# **Setup force equations/acceleration/U\n",
    "\n",
    "#Force equations with J_2\n",
    "x, y, z, J_2, r_earth, mu, r, J_3 = sym.symbols('x y z J_2 r_earth mu r J_3')\n",
    "\n",
    "\n",
    "two_body_J2_string = 'mu/r * ( 1 - J_2*(r_earth/r)**2 * (3/2 * (z/r)**2 - 1/2) )' #potential\n",
    "two_body_J2 = sym.sympify(two_body_J2_string)\n",
    "two_body_J2 = two_body_J2.subs([(r, sym.sqrt(x**2+y**2+z**2))])\n",
    "two_body_J2_acc_x = two_body_J2.diff(x)\n",
    "two_body_J2_acc_y = two_body_J2.diff(y)\n",
    "two_body_J2_acc_z = two_body_J2.diff(z)\n",
    "\n",
    "\n",
    "two_body_J2_acc_x = two_body_J2_acc_x.subs([(r_earth, r_earth_const), (mu, mu_earth), \\\n",
    "                              (J_2, J_2_const)])\n",
    "two_body_J2_acc_y = two_body_J2_acc_y.subs([(r_earth, r_earth_const), (mu, mu_earth), \\\n",
    "                              (J_2, J_2_const)])\n",
    "two_body_J2_acc_z = two_body_J2_acc_z.subs([(r_earth, r_earth_const), (mu, mu_earth), \\\n",
    "                              (J_2, J_2_const)])\n",
    "#print('2 body & J2', two_body_J2_acc_x)\n",
    "\n",
    "x_acc = two_body_J2_acc_x\n",
    "y_acc = two_body_J2_acc_y\n",
    "z_acc = two_body_J2_acc_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add drag to J_2 force equations\n",
    "\n",
    "x_dot, y_dot, z_dot, x_double_dot, y_double_dot, z_double_dot = \\\n",
    "    sym.symbols('x_dot, y_dot, z_dot, x_double_dot, y_double_dot, z_double_dot')\n",
    "    \n",
    "C_D, A, m, density, theta_dot, val, val_dot = \\\n",
    "    sym.symbols('C_D A m density theta_dot val, val_dot')\n",
    "\n",
    "drag_str = ('-(1/2)*C_D*(A/m)*density*'\n",
    "                'sqrt((x_dot+theta_dot*y)**2 + (y_dot-theta_dot*x)**2 +'\n",
    "                'z_dot**2)*(val_dot+theta_dot*val)')\n",
    "drag_symp = sym.sympify(drag_str)\n",
    "\n",
    "drag_symp = drag_symp.subs([(A, A_const), (m, m_const), (C_D, C_D_const),\\\n",
    "                        (theta_dot, theta_dot_const)])\n",
    "\n",
    "\n",
    "x_drag_symp = drag_symp.subs([(r, sym.sqrt(x**2+y**2+z**2)), (val, y), (val_dot, x_dot)])\n",
    "x_acc = x_acc + x_drag_symp\n",
    "\n",
    "y_drag_symp = drag_symp.subs([(r, sym.sqrt(x**2+y**2+z**2)), (val, x), (val_dot, y_dot)])\n",
    "y_acc = y_acc + y_drag_symp\n",
    "\n",
    "z_drag_symp = drag_symp.subs([(r, sym.sqrt(x**2+y**2+z**2)), (val, z), (val_dot, z_dot)])\n",
    "z_acc = z_acc + z_drag_symp\n",
    "    \n",
    "\n",
    "\n",
    "x_acc_sol_fcn = lambdify((x, y, z, x_dot, y_dot, z_dot, density), x_acc)\n",
    "y_acc_sol_fcn = lambdify((x, y, z, x_dot, y_dot, z_dot, density), y_acc)\n",
    "z_acc_sol_fcn = lambdify((x, y, z, x_dot, y_dot, z_dot, density), z_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if (meas_type == 1) or (meas_type == 3):\n",
    "    \n",
    "    x_s, y_s, z_s, x_sf, y_sf, z_sf, theta, theta_dot, t, x_dot, y_dot, z_dot = \\\n",
    "        sym.symbols('x_s, y_s, z_s, x_sf, y_sf, z_sf, theta, theta_dot, t, x_dot, y_dot, z_dot')\n",
    "\n",
    "    #define symbolic rho equation\n",
    "    rho = ('sqrt((x - x_s)**2 + (y - y_s)**2 + (z - z_s)**2)')\n",
    "    rho = sym.sympify(rho)\n",
    "    #sub rotation equation of ecef for eci\n",
    "    rho = rho.subs(x_s, x_sf*sym.cos(omega_const*t) - y_sf*sym.sin(omega_const*t))\n",
    "    rho = rho.subs(y_s, x_sf*sym.sin(omega_const*t) + y_sf*sym.cos(omega_const*t))\n",
    "    rho = rho.subs(z_s, z_sf)\n",
    "\n",
    "    #define symbolic rho dot equation\n",
    "    rho_dot = ('(x*x_dot + y*y_dot + z*z_dot - (x_dot*x_s+y_dot*y_s)*cos(theta) + \\\n",
    "               theta_dot*(x*x_s + y*y_s)*sin(theta) + (x_dot*y_s - y_dot*x_s)*sin(theta) +\\\n",
    "               theta_dot*(x*y_s - y*x_s)*cos(theta) - z_dot*z_s)/ rho')\n",
    "    rho_dot = sym.sympify(rho_dot)\n",
    "    #execute substitutions for rho_dot\n",
    "    rho_dot = rho_dot.subs(x_s, x_sf) \n",
    "    rho_dot = rho_dot.subs(y_s, y_sf) \n",
    "    rho_dot = rho_dot.subs(z_s, z_sf) \n",
    "    rho_dot = rho_dot.subs('rho', rho)\n",
    "    rho_dot = rho_dot.subs(theta, omega_const*t)    \n",
    "    rho_dot = rho_dot.subs(theta_dot, omega_const)\n",
    "\n",
    "    rho_fcn = lambdify(((x, y, z, x_sf, y_sf, z_sf, t)), rho)\n",
    "    rho_dot_fcn = lambdify(((x, y, z, x_dot, y_dot, z_dot, x_sf, y_sf, z_sf, t)), rho_dot)\n",
    "\n",
    "\n",
    "if (meas_type == 2) or (meas_type == 3):\n",
    "    \n",
    "    #x_sf, etc. is the sensor pos in ecef\n",
    "    #x, y, z is the satellite eci\n",
    "    x_s, y_s, z_s, x_sf, y_sf, z_sf, theta, x, y, z, t = \\\n",
    "        sym.symbols('x_s, y_s, z_s, x_sf, y_sf, z_sf, theta, x, y, z, t')\n",
    "    x_L, y_L, z_L, X_L_norm, x_range, y_range, z_range, lon, lat, \\\n",
    "        x_sat_ecef, y_sat_ecef, z_sat_ecef, sen_ecef_norm, omega  = \\\n",
    "        sym.symbols('x_L, y_L, z_L, X_L_norm, x_range, y_range, z_range, lon, lat, \\\n",
    "        x_sat_ecef, y_sat_ecef, z_sat_ecef, sen_ecef_norm, omega')\n",
    "        \n",
    "\n",
    "    #define symbolic rho equation\n",
    "    azimuth = ('atan2(x_L, y_L)') #step 4\n",
    "    azimuth = sym.sympify(azimuth)\n",
    "    \n",
    "    elevation = ('asin(z_L/X_L_norm)') #step 4\n",
    "    elevation = sym.sympify(elevation)\n",
    "    elevation = elevation.subs(X_L_norm, sym.sqrt(x_L**2 + y_L**2 + z_L**2))\n",
    "    \n",
    "    #step 3\n",
    "    azimuth = azimuth.subs([(x_L, -x_range*sym.sin(lon) + y_range*sym.cos(lon)), \\\n",
    "            (y_L, -x_range*sym.sin(lat)*sym.cos(lon) - y_range*sym.sin(lat)*sym.sin(lon) + z_range*sym.cos(lat))])\n",
    "    elevation = elevation.subs([(x_L, -x_range*sym.sin(lon) + y_range*sym.cos(lon)), \\\n",
    "            (y_L, -x_range*sym.sin(lat)*sym.cos(lon) - y_range*sym.sin(lat)*sym.sin(lon) + z_range*sym.cos(lat)), \\\n",
    "            (z_L, x_range*sym.cos(lat)*sym.cos(lon) + y_range*sym.cos(lat)*sym.sin(lon) + z_range*sym.sin(lat))])\n",
    "    \n",
    "    #step 2\n",
    "    azimuth = azimuth.subs([(x_range, x_sat_ecef - x_sf), (y_range, y_sat_ecef - y_sf), \\\n",
    "            (z_range, z_sat_ecef - z_sf), (lat, sym.asin(z_sf/sen_ecef_norm)), (lon, sym.atan2(y_sf, x_sf))])\n",
    "    elevation = elevation.subs([(x_range, x_sat_ecef - x_sf), (y_range, y_sat_ecef - y_sf), \\\n",
    "            (z_range, z_sat_ecef - z_sf), (lat, sym.asin(z_sf/sen_ecef_norm)), (lon, sym.atan2(y_sf, x_sf))])\n",
    "    \n",
    "    #step 1\n",
    "    azimuth = azimuth.subs([(x_sat_ecef, x*sym.cos(theta) + y*sym.sin(theta)), \\\n",
    "                        (y_sat_ecef, -x*sym.sin(theta) + y*sym.cos(theta)), (z_sat_ecef, z), \\\n",
    "                        (sen_ecef_norm, sym.sqrt(x_sf**2 + y_sf**2 + z_sf**2))])\n",
    "    elevation = elevation.subs([(x_sat_ecef, x*sym.cos(theta) + y*sym.sin(theta)), \\\n",
    "                        (y_sat_ecef, -x*sym.sin(theta) + y*sym.cos(theta)), (z_sat_ecef, z), \\\n",
    "                        (sen_ecef_norm, sym.sqrt(x_sf**2 + y_sf**2 + z_sf**2))])\n",
    "    \n",
    "    \n",
    "    azimuth = azimuth.subs([(theta, omega_const*t), (omega, omega_const)])\n",
    "    elevation = elevation.subs([(theta, omega_const*t), (omega, omega_const)])\n",
    "    \n",
    "    azimuth_fcn = lambdify(((x, y, z, x_sf, y_sf, z_sf, t)), azimuth)\n",
    "    elevation_fcn = lambdify(((x, y, z, x_sf, y_sf, z_sf, t)), elevation)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#State and A matrix\n",
    "\n",
    "\n",
    "#define the symbolic state matrix\n",
    "X = sym.Matrix([x, y, z, x_dot, y_dot, z_dot])\n",
    "X_dot = sym.Matrix([x_dot, y_dot, z_dot, x_acc, y_acc, z_acc])\n",
    "    \n",
    "\n",
    "#partial of the force model (x dot) WRT the state vector\n",
    "A_mat = X_dot.jacobian(X)\n",
    "#print(A_mat)\n",
    "\n",
    "A_sol_fcn = lambdify((x, y, z, x_dot, y_dot, z_dot, density), A_mat)\n",
    "#print(A_sol_fcn(1,2,3,4,5,6,7,8))\n",
    "\n",
    "#print(X_dot)\n",
    "X_dot_sol_fcn = lambdify((x, y, z, x_dot, y_dot, z_dot, density), X_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define observation model (G) and H_tilde\n",
    "\n",
    "\n",
    "if meas_type == 1:\n",
    "    G = sym.Matrix([rho, rho_dot])\n",
    "    \n",
    "    \n",
    "elif meas_type == 2:\n",
    "    G = sym.Matrix([azimuth, elevation])\n",
    "    \n",
    "elif meas_type == 3:\n",
    "    G = sym.Matrix([azimuth, elevation, rho])\n",
    "\n",
    "#print(G)\n",
    "G_sol_fcn = lambdify((x, y, z, x_dot, y_dot, z_dot, x_sf, y_sf, z_sf, t), G)\n",
    "\n",
    "#partial derivitive of observation model WRT the state vector\n",
    "X_full = X = sym.Matrix([x, y, z, x_dot, y_dot, z_dot, density])\n",
    "H_tilde = G.jacobian(X_full)\n",
    "#print(H_tilde)\n",
    "H_tilde_sol_fcn = lambdify((x, y, z, x_dot, y_dot, z_dot, x_sf, y_sf, z_sf, t), H_tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def calc_P_TU(X_mean, ensemble):\n",
    "    \n",
    "    dimension = len(X_mean)\n",
    "    \n",
    "    P_bar_sum = np.zeros((dimension, dimension))\n",
    "    \n",
    "    for ii in range(num_of_X_ensembles):\n",
    "\n",
    "        X = ensemble[:, ii].reshape(dimension, 1)\n",
    "        diff_X = X - X_mean\n",
    "        P_bar_sum = P_bar_sum + np.dot(diff_X, diff_X.T)\n",
    "\n",
    "    P_bar = P_bar_sum/(num_of_X_ensembles-1)\n",
    "\n",
    "    return P_bar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 450)\n",
      "[  7.950796762291823e+02   6.701934506850498e+03  -6.279746517887071e+02\n",
      "  -5.805111155451634e+00   1.147516427146103e+00   4.877657130745605e+00]\n"
     ]
    }
   ],
   "source": [
    "#define reference state at epoch, covariance at epoch, and R (using measurement noise)\n",
    "\n",
    "pos_perturbation = 100 * 1e-3 #km\n",
    "vel_perturbation = .1 * 1e-3 #km/s\n",
    "\n",
    "density_dimension = num_of_lat * num_of_lon\n",
    "prob_dimension = 6\n",
    "fullState_dimension = prob_dimension + density_dimension\n",
    "\n",
    "X_ref = np.array([truth_xyz[0,0] + pos_perturbation, truth_xyz[0,1] + pos_perturbation, truth_xyz[0,2] \\\n",
    "            + pos_perturbation, truth_xyz[0,3] + vel_perturbation, truth_xyz[0,4] + vel_perturbation, \\\n",
    "            truth_xyz[0,5] + vel_perturbation])\n",
    "\n",
    "                  \n",
    "P_sigma_pos = 100 * 1e-3 #km\n",
    "P_sigma_vel = .1 * 1e-3 #km/s\n",
    "P_bar_0 = np.diag([P_sigma_pos**2, P_sigma_pos**2, P_sigma_pos**2, \\\n",
    "                   P_sigma_vel**2, P_sigma_vel**2, P_sigma_vel**2, (1e-4)**2]) #(1e-4)**2\n",
    "\n",
    "\n",
    "(L, V) = np.linalg.eig(P_bar_0[:prob_dimension, :prob_dimension]) #eigenvalues, eigenvectors\n",
    "Bsqrt_cov = V * np.sqrt(L)\n",
    "X_ensemble = gen_ensemble(X_ref, Bsqrt_cov, num_of_X_ensembles)\n",
    "print(np.shape(X_ensemble))\n",
    "\n",
    "       \n",
    "                  \n",
    "#Define Measurement Noise\n",
    "if meas_type == 1:\n",
    "    sigma_rho = .1 * 1e-3 #km\n",
    "    sigma_rho_dot = .01 * 1e-3 #km/s\n",
    "    W = np.array([[1/sigma_rho**2, 0], [0, 1/sigma_rho_dot**2]])\n",
    "    R = np.linalg.inv(W)\n",
    "    \n",
    "elif meas_type == 2:\n",
    "    arcsec_per_rad = 206264.806247 #arcsec/rad\n",
    "    noise_rad = (1/arcsec_per_rad)  * 5  #5 arcsec noise (suggested by Moriba for a telescope)\n",
    "    sigma_az = noise_rad\n",
    "    sigma_el = noise_rad\n",
    "    W = np.array([[1/sigma_az**2, 0], [0, 1/sigma_el**2]])\n",
    "    R = np.linalg.inv(W)\n",
    "    \n",
    "elif meas_type == 3:\n",
    "    arcsec_per_rad = 206264.806247 #arcsec/rad\n",
    "    noise_rad = (1/arcsec_per_rad)  * 5  #5 arcsec noise (suggested by Moriba for a telescope)\n",
    "    sigma_az = noise_rad\n",
    "    sigma_el = noise_rad\n",
    "    sigma_rho = .1 * 1e-3 #km\n",
    "    W = np.array([[1/sigma_az**2, 0, 0], [0, 1/sigma_el**2, 0], [0, 0, 1/sigma_rho**2]])\n",
    "    R = np.linalg.inv(W)\n",
    "    \n",
    "    meas_indices = np.array([0, 1, 2])\n",
    "\n",
    "    \n",
    "#reduced rank variable for number of eigvals\n",
    "q = 449\n",
    "    \n",
    "print(X_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#KALMAN\n",
    "\n",
    "def execute_enkf(obs_data, X_ensemble, P, R, density_state_ensemble,\\\n",
    "                         prob_dimension, density_dimension, stop_index):\n",
    "    \n",
    "    #initializations\n",
    "    Q_ECI = np.zeros((6,6))\n",
    "    \n",
    "    num_of_meas = np.shape(R)[0]\n",
    "    X_mean_updated = np.sum(X_ensemble, axis=1)/num_of_X_ensembles\n",
    "\n",
    "    post_fit_list = np.zeros((stop_index, num_of_meas))\n",
    "\n",
    "    P_list = np.zeros((stop_index, prob_dimension+1, prob_dimension+1))\n",
    "    X_mean_updated_list = np.zeros((stop_index, prob_dimension+1))\n",
    "    \n",
    "    density_MSIS_array = np.zeros(stop_index)\n",
    "    est_density_array = np.zeros(stop_index)\n",
    "    #est_density_grid_array = np.zeros((stop_index, num_of_lat, num_of_lon))\n",
    "\n",
    "    \n",
    "    X_distribution = np.zeros((prob_dimension, num_of_X_ensembles, stop_index))\n",
    "    density_distribution = np.zeros((num_of_ensembles, stop_index))\n",
    "    lat_lst_array = np.zeros((2, stop_index))\n",
    "    X_density_ensemble = np.zeros((fullState_dimension, num_of_X_ensembles))\n",
    "    \n",
    "    \n",
    "    #reduced rank\n",
    "    dens_ens = density_state_ensemble.reshape(num_of_ensembles, density_dimension).T\n",
    "    X_density_ensemble = np.zeros((fullState_dimension, num_of_X_ensembles))\n",
    "    X_density_ensemble[:6, :] = X_ensemble\n",
    "    X_density_ensemble[6:, :] = dens_ens\n",
    "\n",
    "    \n",
    "    #mean of X state & density state over ensemble\n",
    "    X_bar = np.sum(X_density_ensemble, axis=1).reshape(fullState_dimension,1)/num_of_X_ensembles\n",
    "    P = calc_P_TU(X_bar, X_density_ensemble)\n",
    "    \n",
    "    eigvals, eigvecs = np.linalg.eig(P)\n",
    "    eigvec_truncated = eigvecs[:, :q]\n",
    "    eigvals_truncated = eigvals[:q]\n",
    "    S = np.dot(eigvec_truncated, np.diag(np.sqrt(eigvals_truncated)))\n",
    "    P = np.dot(S, S.T)\n",
    "    \n",
    "\n",
    "    for obsnum in range(len(obs_data[:stop_index])):\n",
    "        \n",
    "        print(obsnum, obs_data[obsnum, 0])\n",
    "        \n",
    "        \n",
    "        time = obs_data[obsnum, 0]\n",
    "        t_init = obs_data[obsnum-1, 0] \n",
    "        if obsnum == 0:\n",
    "            t_init = obs_data[obsnum, 0]\n",
    "            \n",
    "        #save true MSIS density for this time step (which is density at beginning of time used to prop for this step)\n",
    "        density_MSIS = filter_functions.calc_MSIS_density(time, X_mean_updated, day_of_year_init, day_of_month_init, \\\n",
    "                                                hour_init_UT, month_init, year_init, omega_const, r_earth_const)\n",
    "        density_MSIS = density_MSIS * 1e9  #convert from kg/m**3 to kg/km**3\n",
    "        density_MSIS_array[obsnum] = density_MSIS\n",
    "        \n",
    "        \n",
    "        #determine density to be used in propagation\n",
    "        (lat_grid_ticks, lst_grid_ticks) = filter_functions.calc_lat_lst_indices(t_init, \\\n",
    "                            X_mean_updated[:3].reshape(3,1), day_of_month_init, hour_init_UT, month_init, \\\n",
    "                                   year_init, omega_const, r_earth_const, lat_res, lon_res)\n",
    "        \n",
    "        latt = np.degrees(latitude_grid[lat_grid_ticks])\n",
    "        lonn = np.degrees(longitude_grid[lst_grid_ticks])\n",
    "        \n",
    "        lat_meas = lat_lst_meas_array[obsnum-1, 0]\n",
    "        lon_meas = lat_lst_meas_array[obsnum-1, 1]\n",
    "        \n",
    "        densities = density_state_ensemble[:, lat_grid_ticks, lst_grid_ticks]\n",
    "\n",
    "\n",
    "        result = X_ensemble\n",
    "\n",
    "        if (obs_data[obsnum, 0] != obs_data[obsnum-1, 0]) and (obsnum != 0):\n",
    "            \n",
    "            result = np.zeros((prob_dimension, num_of_X_ensembles))\n",
    "\n",
    "            for ii in range(num_of_X_ensembles):\n",
    "                #set the initial values for the propogator:\n",
    "                y0 = X_ensemble[:, ii]\n",
    "                density = densities[ii]\n",
    "            \n",
    "                integrator = ode(orbitpropogator_EnKF)\n",
    "                integrator.set_integrator('dopri5', nsteps=1e6, rtol=1e-12, atol=1e-12)\n",
    "                integrator.set_f_params(density)\n",
    "                integrator.set_initial_value(y0, t_init)\n",
    "                integrator.integrate(time)\n",
    "                result[:, ii] = integrator.y\n",
    "\n",
    "        X_ensemble = result.reshape(prob_dimension, num_of_X_ensembles)\n",
    "        \n",
    "        \n",
    "        #create array that holds X state ensemble & density state ensemble combined\n",
    "        density_state = density_state_ensemble[:, lat_grid_ticks, lst_grid_ticks]\n",
    "        X_density_ensemble[:6, :] = X_ensemble\n",
    "        X_density_ensemble[6:, :] = density_state_ensemble.reshape(num_of_ensembles, density_dimension).T \n",
    "        #****density_state\n",
    "        \n",
    "        #mean of X state & density state over ensemble\n",
    "        X_bar = np.sum(X_density_ensemble, axis=1).reshape(fullState_dimension,1)/num_of_X_ensembles\n",
    "        \n",
    "        #calculate Time Updated P\n",
    "        #P_TU = calc_P_TU(X_bar, X_density_ensemble)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        #determine station coordinates for observation eq.\n",
    "        if int(obs_data[obsnum, 1]) == 1:\n",
    "            #print('1')\n",
    "            station_index = 0\n",
    "            X_s = r_ecef_dss34\n",
    "        if int(obs_data[obsnum, 1]) == 2:\n",
    "            #print('2')\n",
    "            station_index = 1\n",
    "            X_s = r_ecef_dss65\n",
    "        if int(obs_data[obsnum, 1]) == 3:\n",
    "            #print('3')\n",
    "            station_index = 2\n",
    "            X_s = r_ecef_dss13\n",
    "        if int(obs_data[obsnum, 1]) == 4:\n",
    "            #print('amos')\n",
    "            station_index = 3\n",
    "            X_s = r_ecef_diego\n",
    "\n",
    "        \n",
    "        #-------------------Measurement Update--------------------------------------------------------\n",
    "        print(np.all(np.linalg.eigvals(P) > 0))\n",
    "        \n",
    "        if obsnum == 23:\n",
    "             Tracer() ()\n",
    "      \n",
    "        \n",
    "        H = np.zeros((num_of_meas, fullState_dimension))\n",
    "        H[:num_of_meas, :prob_dimension+1] = H_tilde_sol_fcn(*X_bar[:6,0], *X_s, time)\n",
    "        \n",
    "       \n",
    "        V = np.dot(H, S)\n",
    "        W = np.dot(V.T, np.dot(np.linalg.inv(R), V))\n",
    "        \n",
    "        eigvals, eigvecs = np.linalg.eig(W)\n",
    "        U_tilde = eigvecs[:, :q]\n",
    "        cap_lambda_tilde = np.diag(eigvals[:q])\n",
    "        \n",
    "        part1 = np.linalg.inv(np.sqrt(np.eye(q) + cap_lambda_tilde)) #should be diag\n",
    "        S = np.dot(S, np.dot(U_tilde, part1))\n",
    "        \n",
    "\n",
    "        \n",
    "        part1 = np.dot(P, H.T)\n",
    "        part2 = np.dot(H, np.dot(P, H.T))\n",
    "        K = np.dot(part1, np.linalg.inv(part2 + R))\n",
    "        \n",
    "        \n",
    "        Hx_array = np.zeros((num_of_meas, num_of_X_ensembles))\n",
    "        Hx = np.zeros(3)\n",
    "        for ii in range(num_of_X_ensembles):\n",
    "            \n",
    "            X = X_ensemble[:, ii]\n",
    "\n",
    "            Hx = G_sol_fcn(*X, *X_s, time)\n",
    "            \n",
    "            if (meas_type != 1) and (Hx[0] < 0): #if az less than 0, add 2*pi\n",
    "                Hx[0] = Hx[0] + 2*math.pi\n",
    "\n",
    "            Hx_array[:, ii] = Hx.reshape(num_of_meas)\n",
    "        \n",
    "        \n",
    "        #get actual observation\n",
    "        y_observed = obs_data[obsnum, 2:(2+num_of_meas)].reshape(num_of_meas,1)\n",
    "        \n",
    "        \n",
    "        X_density_ensemble_updated = np.zeros((fullState_dimension, num_of_X_ensembles))\n",
    "        #**correction_array = np.zeros((1, num_of_X_ensembles))\n",
    "        for ii in range(num_of_X_ensembles):\n",
    "            \n",
    "            e = np.sqrt(np.diag(R)).reshape(num_of_meas, 1) * np.random.randn(num_of_meas, 1)\n",
    "            \n",
    "            correction = np.dot(K, (y_observed + e - Hx_array[:, ii].reshape(num_of_meas, 1)))\n",
    "            \n",
    "            X_member_updated = X_density_ensemble[:, ii].reshape(fullState_dimension, 1) + correction\n",
    "                \n",
    "            X_density_ensemble_updated[:, ii] = X_member_updated.reshape(fullState_dimension)\n",
    "        \n",
    "        \n",
    "        \n",
    "        P = np.dot(S, S.T)\n",
    "        \n",
    "    \n",
    "        \n",
    "        #update overall density grid ensemble with this lat/lon's updated density values \n",
    "        updated_density_portion = X_density_ensemble_updated[6:,:].T.reshape(num_of_ensembles, num_of_lat, num_of_lon)\n",
    "        density_state_ensemble = copy.deepcopy(updated_density_portion) \n",
    "        #est_density_grid_array[obsnum] = np.mean(density_state_ensemble, axis=0)\n",
    "        \n",
    "\n",
    "        est_density_array[obsnum] = np.sum(updated_density_portion[:, lat_grid_ticks, lst_grid_ticks])\\\n",
    "                                                                                            /num_of_ensembles\n",
    "            \n",
    "        #save values\n",
    "        X_mean_updated = np.zeros((7))\n",
    "        X_mean_updated[:6] = np.sum(X_density_ensemble_updated[:6,:], axis=1)/num_of_X_ensembles\n",
    "        X_mean_updated[6:] = est_density_array[obsnum]\n",
    "        X_mean_updated_list[obsnum, :] = X_mean_updated\n",
    "        \n",
    "        #save values for analysis of distributions and such\n",
    "        density_distribution[:, obsnum] = updated_density_portion[:, lat_grid_ticks, lst_grid_ticks] \n",
    "        X_distribution[:, :, obsnum] = X_density_ensemble_updated[:6, :]\n",
    "        lat_lst_array[:, obsnum] = np.array([latitude_grid[lat_grid_ticks], longitude_grid[lst_grid_ticks]]).reshape(2)\n",
    "\n",
    "      \n",
    "        \n",
    "        \n",
    "        P_list[obsnum, :6, :6] = P[:6, :6]\n",
    "        P_list[obsnum, -1, -1] = P[0,6:].reshape(num_of_lat, num_of_lon)[lat_grid_ticks, lst_grid_ticks]\n",
    "\n",
    "\n",
    "        #-------------RMS / Residuals-------------\n",
    "        Hx = G_sol_fcn(*X_mean_updated[:6], *X_s, time)\n",
    "        if Hx[0] < 0:\n",
    "            Hx[0] = Hx[0] + 2*math.pi\n",
    "        post_fit_resid = y_observed - Hx.reshape(num_of_meas, 1)\n",
    "        post_fit_list[obsnum, :] = post_fit_resid.reshape(num_of_meas) \n",
    "        \n",
    "\n",
    "        #Prep for next time step\n",
    "        X_ensemble = X_density_ensemble_updated[:6, :]\n",
    "\n",
    "    \n",
    "    \n",
    "    return (X_mean_updated_list, P_list, post_fit_list, density_MSIS_array, est_density_array, X_distribution, \\\n",
    "            density_distribution, lat_lst_array, updated_density_portion, X_ensemble)#, est_density_grid_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5410.0\n",
      "False\n",
      "1 5420.0\n",
      "False\n",
      "2 5430.0\n",
      "False\n",
      "3 5440.0\n",
      "False\n",
      "4 5450.0\n",
      "False\n",
      "5 5460.0\n",
      "False\n",
      "6 5470.0\n",
      "False\n",
      "7 5480.0\n",
      "False\n",
      "8 5490.0\n",
      "False\n",
      "9 5500.0\n",
      "False\n",
      "10 5510.0\n",
      "False\n",
      "11 5520.0\n",
      "False\n",
      "12 5530.0\n",
      "False\n",
      "13 5540.0\n",
      "False\n",
      "14 5550.0\n",
      "False\n",
      "15 5560.0\n",
      "False\n",
      "16 5570.0\n",
      "False\n",
      "17 5580.0\n",
      "False\n",
      "18 5590.0\n",
      "False\n",
      "19 5600.0\n",
      "False\n",
      "20 5610.0\n",
      "False\n",
      "21 5620.0\n",
      "False\n",
      "22 5630.0\n",
      "False\n",
      "23 5640.0\n",
      "False\n",
      "> \u001b[0;32m<ipython-input-13-7c2ce64a4c53>\u001b[0m(135)\u001b[0;36mexecute_enkf\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    133 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    134 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 135 \u001b[0;31m        \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_of_meas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullState_dimension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    136 \u001b[0;31m        \u001b[0mH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_of_meas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mprob_dimension\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH_tilde_sol_fcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX_bar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mX_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    137 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n",
      "Exiting Debugger.\n"
     ]
    }
   ],
   "source": [
    "#Call EnKF\n",
    "\n",
    "\n",
    "stop_index = 50 #558 * 3 #92.56 minutes #/2\n",
    "\n",
    "(X_mean_updated_list_EnKF, P_list_EnKF, post_fit_list_EnKF, density_MSIS_array, est_density_array,\\\n",
    "X_distribution, density_distribution, lat_lst_array, updated_density_portion, X_ensemble) = \\\n",
    "            execute_enkf(measurement_array, X_ensemble, P_bar_0, R, ensembles_of_density_grid,\\\n",
    "                         prob_dimension, density_dimension, stop_index)\n",
    "    \n",
    "#, est_density_grid_array) = \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save Results\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "save_density_grid = True #save time series of density grid, True if saved the est. density grid within EnKF\n",
    "\n",
    "\n",
    "if save_density_grid == False:\n",
    "\n",
    "    #generate density grid for final time in order to compare entire final density grid estimate to truth\n",
    "    alt = np.linalg.norm(X_mean_updated_list_EnKF[-1,:3]) - r_earth_const\n",
    "\n",
    "    final_density_grid_truth = filter_functions.gen_one_ensemble(latitude_grid, longitude_grid, alt,\\\n",
    "                                                        day_of_year_init, measurement_array[stop_index-1,0]) #final time\n",
    "   \n",
    "    mydict = {'X_mean_updated_list_EnKF': X_mean_updated_list_EnKF, 'P_list_EnKF': P_list_EnKF, \\\n",
    "          'post_fit_list_EnKF': post_fit_list_EnKF, 'density_MSIS_array': density_MSIS_array, \\\n",
    "          'est_density_array': est_density_array, 'X_distribution': X_distribution, \\\n",
    "          'density_distribution': density_distribution, 'lat_lst_array': lat_lst_array,\n",
    "         'final_density_ensemble_est': updated_density_portion, 'final_X_ensemble': X_ensemble,\\\n",
    "        'true_density_array': true_density_array, \\\n",
    "          'final_density_grid_truth': final_density_grid_truth*1e9, 'measurement_array': measurement_array, \\\n",
    "             'truth_xyz': truth_xyz, 'lat_lst_meas_array': lat_lst_meas_array}\n",
    "\n",
    "\n",
    "    output = open('Figures/Results.pkl', 'wb')\n",
    "    pickle.dump(mydict, output)\n",
    "    output.close()\n",
    "\n",
    "\n",
    "    #MATLAB file\n",
    "\n",
    "    filename = 'Data Files/Results.mat'\n",
    "\n",
    "    import scipy.io\n",
    "    scipy.io.savemat(filename, mdict={'X_mean_updated_list_EnKF': X_mean_updated_list_EnKF, 'P_list_EnKF': P_list_EnKF, \\\n",
    "              'post_fit_list_EnKF': post_fit_list_EnKF, 'density_MSIS_array': density_MSIS_array, \\\n",
    "              'est_density_array': est_density_array, 'X_distribution': X_distribution, \\\n",
    "              'density_distribution': density_distribution, 'lat_lst_array': lat_lst_array,\n",
    "             'final_density_ensemble_est': updated_density_portion, 'final_X_ensemble': X_ensemble,\n",
    "            'true_density_array': true_density_array, \n",
    "            'final_density_grid_truth': final_density_grid_truth*1e9, 'measurement_array': measurement_array, \\\n",
    "             'truth_xyz': truth_xyz, 'lat_lst_meas_array': lat_lst_meas_array})\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "if save_density_grid:\n",
    "\n",
    "    final_density_grid_truth_timeSeries = np.zeros((stop_index, num_of_lat, num_of_lon))    \n",
    "\n",
    "    for ii in range(stop_index):\n",
    "\n",
    "        #generate density grid for final time in order to compare entire final density grid estimate to truth\n",
    "        alt = np.linalg.norm(X_mean_updated_list_EnKF[ii,:3]) - r_earth_const\n",
    "        final_density_grid_truth_timeSeries[ii] = filter_functions.gen_one_ensemble(latitude_grid, longitude_grid, alt,\\\n",
    "                                                    day_of_year_init, measurement_array[ii,0]) #final time\n",
    "\n",
    "    #PKL file\n",
    "\n",
    "    mydict = {'X_mean_updated_list_EnKF': X_mean_updated_list_EnKF, 'P_list_EnKF': P_list_EnKF, \\\n",
    "              'post_fit_list_EnKF': post_fit_list_EnKF, 'density_MSIS_array': density_MSIS_array, \\\n",
    "              'est_density_array': est_density_array, 'X_distribution': X_distribution, \\\n",
    "              'density_distribution': density_distribution, 'lat_lst_array': lat_lst_array,\n",
    "             'final_density_ensemble_est': updated_density_portion, 'final_X_ensemble': X_ensemble,\\\n",
    "            'true_density_array': true_density_array, \\\n",
    "              'final_density_grid_truth_timeSeries': final_density_grid_truth_timeSeries*1e9,\n",
    "             'est_density_grid_array': est_density_grid_array, 'measurement_array': measurement_array, \\\n",
    "             'truth_xyz': truth_xyz, 'lat_lst_meas_array': lat_lst_meas_array}\n",
    "\n",
    "    output = open('Figures/Results.pkl', 'wb')\n",
    "    pickle.dump(mydict, output)\n",
    "    output.close()\n",
    "\n",
    "\n",
    "\n",
    "    #MATLAB file\n",
    "\n",
    "    filename = 'Data Files/Results.mat'\n",
    "\n",
    "    import scipy.io\n",
    "    scipy.io.savemat(filename, mdict={'X_mean_updated_list_EnKF': X_mean_updated_list_EnKF, 'P_list_EnKF': P_list_EnKF, \\\n",
    "              'post_fit_list_EnKF': post_fit_list_EnKF, 'density_MSIS_array': density_MSIS_array, \\\n",
    "              'est_density_array': est_density_array, 'X_distribution': X_distribution, \\\n",
    "              'density_distribution': density_distribution, 'lat_lst_array': lat_lst_array,\n",
    "             'final_density_ensemble_est': updated_density_portion, 'final_X_ensemble': X_ensemble,\n",
    "            'true_density_array': true_density_array, \n",
    "            'final_density_grid_truth_timeSeries': final_density_grid_truth_timeSeries*1e9,\n",
    "            'est_density_grid_array': est_density_grid_array, 'measurement_array': measurement_array, \\\n",
    "             'truth_xyz': truth_xyz, 'lat_lst_meas_array': lat_lst_meas_array})\n",
    "\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Data (from saved run) in to Generate Results\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# read python dict containing densities\n",
    "results_file = open('Figures/12Periods_trulyObs_0RAAN/Results.pkl', 'rb') #Results_1Period/Results_558.pkl\n",
    "mydict = pickle.load(results_file)\n",
    "results_file.close()\n",
    "\n",
    "X_mean_updated_list_EnKF = mydict['X_mean_updated_list_EnKF'] \n",
    "P_list_EnKF = mydict['P_list_EnKF'] \n",
    "post_fit_list_EnKF = mydict['post_fit_list_EnKF'] \n",
    "density_MSIS_array = mydict['density_MSIS_array'] \n",
    "est_density_array = mydict['est_density_array'] \n",
    "X_distribution = mydict['X_distribution'] \n",
    "density_distribution = mydict['density_distribution'] \n",
    "lat_lst_array = mydict['lat_lst_array']\n",
    "final_density_ensemble_est = mydict['final_density_ensemble_est']\n",
    "final_X_ensemble = mydict['final_X_ensemble']\n",
    "true_density_array = mydict['true_density_array']\n",
    "final_density_grid_truth_timeSeries = mydict['final_density_grid_truth_timeSeries']\n",
    "est_density_grid_array = mydict['est_density_grid_array']\n",
    "\n",
    "                \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "times = measurement_array[:stop_index, 0]/(60)\n",
    "\n",
    "time_str = 'Time (minutes)'\n",
    "\n",
    "time_repeated_ensemble = np.repeat(times[:stop_index], num_of_ensembles)\n",
    "time_repeated_X = np.repeat(times[:stop_index], num_of_X_ensembles)\n",
    "\n",
    "#\"\"\"\n",
    "#calculate the normed density distribution by subtracting the mean of the ensemble from each ensemble   \n",
    "#density_distribution shape = num_of_ensembles x stop_index\n",
    "density_distribution_mean = np.mean(density_distribution[:,:stop_index], axis=0).reshape(1, stop_index)\n",
    "\n",
    "density_distribution_mean_tiled = np.tile(density_distribution_mean, (1, num_of_X_ensembles))\n",
    "density_distribution_mean_tiled = density_distribution_mean_tiled.reshape(num_of_X_ensembles, stop_index)\n",
    "\n",
    "density_distribution_normed = density_distribution[:, :stop_index] - density_distribution_mean_tiled\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(time_repeated_ensemble, density_distribution_normed.T.flatten())\n",
    "plt.ylabel(r'Distribution $(kg/km^3)$', fontsize=18)\n",
    "plt.xlabel(time_str, fontsize=18)\n",
    "plt.ylim(-.5e-3, .5e-3)\n",
    "plt.title('Density Ensemble Distribution (normed by mean)', fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#calculate the normed density distribution by subtracting the truth of the ensemble from each ensemble   \n",
    "#density_distribution shape = num_of_ensembles x stop_index\n",
    "density_distribution_truth = density_MSIS_array[:stop_index].reshape(1, stop_index)\n",
    "density_distribution_normed = density_distribution[:, :stop_index] - \\\n",
    "                    np.tile(density_distribution_truth, (num_of_ensembles, 1))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(time_repeated_ensemble, density_distribution_normed.T.flatten())\n",
    "plt.ylabel(r'Distribution $(kg/km^3)$', fontsize=18)\n",
    "plt.xlabel(time_str, fontsize=18)\n",
    "plt.ylim(-1e-2, 1e-2)\n",
    "plt.title('Density Ensemble Distribution (normed by truth/MSIS)', fontsize=18)\n",
    "plt.show()\n",
    "#\"\"\"\n",
    "\n",
    "#calculate the normed X pos distribution by subtracting the mean of the ensemble from each ensemble   \n",
    "#X_distribution shape = 6 x num_of_X_ensembles x stop_index\n",
    "X_distribution_Xpos = X_distribution[0,:,:stop_index]\n",
    "X_distribution_Xpos_mean = np.mean(X_distribution_Xpos, axis=0).reshape(1, stop_index)\n",
    "X_distribution_Xpos_mean_tiled = np.tile(X_distribution_Xpos_mean, (1, num_of_X_ensembles))\n",
    "X_distribution_Xpos_mean_tiled = X_distribution_Xpos_mean_tiled.reshape(num_of_X_ensembles, stop_index)\n",
    "X_distribution_Xpos_diff = X_distribution_Xpos - X_distribution_Xpos_mean_tiled\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(time_repeated_X, X_distribution_Xpos_diff.T.flatten())\n",
    "plt.ylabel(r'Distribution (km)', fontsize=18)\n",
    "plt.xlabel(time_str, fontsize=18)\n",
    "#plt.ylim(-1e-4,1e-4)\n",
    "plt.title('State X Position Ensemble Distribution (normed by mean)', fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#calculate the normed X pos distribution by subtracting the truth of the ensemble from each ensemble   \n",
    "#X_distribution shape = 6 x num_of_X_ensembles x stop_index\n",
    "X_distribution_Xpos_truth = truth_xyz[:stop_index, 0].reshape(1, stop_index)\n",
    "X_distribution_Xpos_truth_normed = X_distribution_Xpos - np.tile(X_distribution_Xpos_truth, (num_of_ensembles, 1))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(time_repeated_ensemble, X_distribution_Xpos_truth_normed.T.flatten())\n",
    "plt.ylabel(r'Distribution (km)', fontsize=18)\n",
    "plt.xlabel(time_str, fontsize=18)\n",
    "#plt.ylim(-1e-4, 1e-4)\n",
    "plt.title('State X Position Ensemble Distribution (normed by truth)', fontsize=18)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#stop_index = 10\n",
    "\n",
    "\n",
    "times = measurement_array[:stop_index, 0]/(60)\n",
    "\n",
    "time_repeated_ensemble = np.repeat(times[:stop_index], num_of_ensembles)\n",
    "time_repeated_X = np.repeat(times[:stop_index], num_of_X_ensembles)\n",
    "\n",
    "\n",
    "fig_lat = plt.figure()\n",
    "plt.scatter(times, np.degrees(lat_lst_meas_array[:stop_index, 0]), s=70, c='b',marker='+')\n",
    "plt.scatter(times, np.degrees(lat_lst_array[0,:stop_index]), s=70, c='c',marker='+')\n",
    "plt.ylabel('Degrees', fontsize=18)\n",
    "plt.xlabel(time_str, fontsize=18)\n",
    "plt.title('Latitude', fontsize=18)\n",
    "legend_names = ['Meas Truth', 'EnKF']\n",
    "plt.legend(legend_names, fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "fig_LST = plt.figure()\n",
    "plt.scatter(times, np.degrees(lat_lst_meas_array[:stop_index, 1]), s=70, c='b', marker='+')\n",
    "plt.scatter(times, np.degrees(lat_lst_array[1,:stop_index]), s=70, c='c', marker='+')\n",
    "plt.ylabel('Degrees', fontsize=18)\n",
    "plt.xlabel(time_str, fontsize=18)\n",
    "plt.title('LST', fontsize=18)\n",
    "legend_names = ['Meas Truth', 'EnKF']\n",
    "plt.legend(legend_names, fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig_density_comparison = plt.figure()\n",
    "plt.scatter(times, density_MSIS_array[:stop_index], s=70, c='c', marker='+')\n",
    "plt.scatter(times, true_density_array[:stop_index], s=70, c='b', marker='+')\n",
    "#plt.ylim([-1e-11,1e-11])\n",
    "plt.ylabel(r'$kg/km^3$', fontsize=18)\n",
    "plt.xlabel(time_str, fontsize=18)\n",
    "plt.ylim([0,2e-3])\n",
    "plt.title('MSIS/True Density v. Meas Gen Density', fontsize=18)\n",
    "legend_names = ['MSIS', 'Meas Truth']\n",
    "plt.legend(legend_names, fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig_density_comparison = plt.figure()\n",
    "plt.scatter(times, density_MSIS_array[:stop_index], s=70, c='c', marker='+')\n",
    "plt.scatter(times, est_density_array[:stop_index], s=70, c='b', marker='+')\n",
    "#plt.ylim([-1e-11,1e-11])\n",
    "plt.ylabel(r'$kg/km^3$', fontsize=18)\n",
    "plt.xlabel(time_str, fontsize=18)\n",
    "plt.ylim([0,2e-3])\n",
    "plt.title('Estimated v. MSIS/True Density', fontsize=18)\n",
    "legend_names = ['MSIS', 'Estimated']\n",
    "plt.legend(legend_names, fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig_density_comparison = plt.figure()\n",
    "plt.scatter(times, true_density_array[:stop_index], s=70, c='b', marker='+')\n",
    "plt.scatter(times, est_density_array[:stop_index], s=70, c='c', marker='+')\n",
    "#plt.ylim([-1e-11,1e-11])\n",
    "plt.ylabel(r'$kg/km^3$', fontsize=18)\n",
    "plt.xlabel(time_str, fontsize=18)\n",
    "plt.ylim([0,2e-3])\n",
    "plt.title('Estimated v. Meas Gen True Density', fontsize=18)\n",
    "legend_names = ['Meas', 'Estimated']\n",
    "plt.legend(legend_names, fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "perc_error = 100 * np.absolute(est_density_array[:stop_index] - true_density_array[:stop_index])/true_density_array[:stop_index]\n",
    "\n",
    "fig_percent = plt.figure()\n",
    "plt.scatter(times, perc_error[:stop_index], s=70, c='b', marker='+')\n",
    "#plt.ylim([-1e-11,1e-11])\n",
    "plt.ylabel('Percent', fontsize=18)\n",
    "plt.xlabel(time_str, fontsize=18)\n",
    "plt.title('Percent Error of Estimated Density (w/ meas gen truth)', fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "mean = np.mean(est_density_array[:stop_index])\n",
    "est_density_array_normalized = est_density_array[:stop_index] - mean\n",
    "\n",
    "fig_est = plt.figure()\n",
    "plt.scatter(times, est_density_array_normalized[:stop_index], s=70, c='b', marker='+')\n",
    "plt.ylabel(r'$kg/km^3$', fontsize=18)\n",
    "plt.xlabel(time_str, fontsize=18)\n",
    "plt.title('Normalized Estimated Density', fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "fig_lat.savefig('Figures/latitude.png')\n",
    "fig_LST.savefig('Figures/LST.png')\n",
    "fig_density_comparison.savefig('Figures/density_comparison.png')\n",
    "fig_percent.savefig('Figures/percent.png')\n",
    "fig_est.savefig('Figures/est_density.png')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Rank Histograms\n",
    "\n",
    "\n",
    "#Density\n",
    "\n",
    "rank_array = np.zeros((stop_index, 1))\n",
    "\n",
    "for ii in range(stop_index):\n",
    "    \n",
    "    new_array = np.append(density_distribution[:, ii], density_MSIS_array[ii])\n",
    "    \n",
    "    rank = scipy.stats.rankdata(new_array, method='min')[-1]\n",
    "    \n",
    "    rank_array[ii] = rank\n",
    "    \n",
    "indices = np.where(rank_array != 450)[0]\n",
    "indices1 = np.where(rank_array == 450)[0]\n",
    "print(times[indices1])\n",
    "\n",
    "\n",
    "fig_rank_hist = plt.figure()\n",
    "plt.hist(rank_array, bins=451)\n",
    "plt.ylabel('Frequency', fontsize=18)\n",
    "plt.xlabel('Rank', fontsize=18)\n",
    "plt.title('Density Ensemble Rank Histogram', fontsize=18)\n",
    "plt.xlim([0,451])\n",
    "plt.show()\n",
    "\n",
    "#fig_rank_hist.savefig('Figures/rank_hist.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Generate Plots for Analysis\n",
    "\n",
    "x_range = .005\n",
    "y_range = .05\n",
    "z_range = .05\n",
    "\n",
    "xv_range = 1e-4\n",
    "yv_range = 1e-4\n",
    "zv_range = 1e-4\n",
    "\n",
    "times = measurement_array[:, 0]\n",
    "\n",
    "saveFig_bool = False\n",
    "\n",
    "\n",
    "filter_functions.calc_display_results(post_fit_list_EnKF, measurement_array, R, meas_type, stop_index, saveFig_bool,\\\n",
    "                                     time_str)\n",
    "\n",
    "\n",
    "filter_functions.plot_error_covar_xref(P_list_EnKF, X_mean_updated_list_EnKF, \\\n",
    "                      truth_xyz, true_density_array, x_range, y_range, z_range, xv_range, yv_range, zv_range,\\\n",
    "                      measurement_array, times, stop_index, saveFig_bool, time_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.where(measurement_array[:, 1] == 1)[0]\n",
    "print(indices)\n",
    "indices = np.where(measurement_array[:, 1] == 2)[0]\n",
    "print(indices)\n",
    "indices = np.where(measurement_array[:, 1] == 3)[0]\n",
    "print(indices)\n",
    "indices = np.where(measurement_array[:, 1] == 4)[0]\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
