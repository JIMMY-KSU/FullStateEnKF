{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import sympy as sym\n",
    "from scipy.integrate import ode\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "import pickle\n",
    "import filter_functions\n",
    "import copy\n",
    "from IPython.core.debugger import Tracer\n",
    "from sympy.utilities.lambdify import lambdify\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=15)\n",
    "sym.init_printing()\n",
    "\n",
    "#MSIS: https://github.com/DeepHorizons/Python-NRLMSISE-00\n",
    "#import time\n",
    "from nrlmsise_00_header import *\n",
    "from nrlmsise_00 import *\n",
    "#SUBROUTINE GTD7D -- d[5] is the \"effective total mass density\n",
    "#for drag\" and is the sum of the mass densities of all species\n",
    "#in this model, INCLUDING anomalous oxygen.\n",
    "\n",
    "#define constants\n",
    "r_earth_const = 6378136.3 #meters\n",
    "omega_const = 7.2921158553e-5\n",
    "J_2_const = .00108262617385222\n",
    "J_3_const = -.00000253241051856772\n",
    "mu_earth = 3.986004415e14 #m^3/s^2\n",
    "\n",
    "\n",
    "#Drag:\n",
    "A_const = 0.9551567 #meters^2; cross-sectional area of satellite\n",
    "m_const = 10 #kg; mass of satellite\n",
    "C_D_const = 2.0\n",
    "theta_dot_const = 7.2921158553e-5 #rad/sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "meas_type = 3\n",
    "\n",
    "if meas_type == 1:\n",
    "    meas_file = open('Data Files/meas_range_rangeRate.pkl', 'rb')\n",
    "elif meas_type == 2:\n",
    "    meas_file = open('Data Files/meas_az_el.pkl', 'rb')\n",
    "elif meas_type == 3:\n",
    "    meas_file = open('Data Files/meas_az_el_range.pkl', 'rb')\n",
    "    \n",
    "\n",
    "if meas_type == 3:\n",
    "    num_of_meas = 3\n",
    "else:\n",
    "    num_of_meas = 2\n",
    "\n",
    "    \n",
    "#Date of Simulation Details:\n",
    "#June 24th, 2017 at 6am (this is the date & time at the beginning of the simulation/orbit)\n",
    "year_init = 2017\n",
    "month_init = 6\n",
    "day_init = 24\n",
    "hour_init = 6\n",
    "boulder_UT_offset = 6 #Boulder time + 6 hours = UT time\n",
    "hour_init_UT = hour_init + boulder_UT_offset\n",
    "    \n",
    "    \n",
    "\n",
    "#Canbera Station (DSS 34)\n",
    "lat_dss34 = math.radians(-35.398333)\n",
    "lon_dss34 = math.radians(148.981944)\n",
    "alt_dss34 = 691.75 #m\n",
    "\n",
    "r_ecef_dss34 = filter_functions.topo2ecef(lat_dss34, lon_dss34, alt_dss34, r_earth_const)\n",
    "#print(r_ecef_dss34)\n",
    "\n",
    "#Madrid Station (DSS 65) -- correct position of Madrid Station\n",
    "lat_dss65 = math.radians(40.427222)\n",
    "lon_dss65 = math.radians(355.749444)\n",
    "alt_dss65 = 834.539 #m\n",
    "\n",
    "r_ecef_dss65 = filter_functions.topo2ecef(lat_dss65, lon_dss65, alt_dss65, r_earth_const)\n",
    "#print(r_ecef_dss65)\n",
    "\n",
    "#Goldstone Station (DSS 13) \n",
    "lat_dss13 = math.radians(35.247164)\n",
    "lon_dss13 = math.radians(243.205)\n",
    "alt_dss13 = 1071.14904 #m\n",
    "\n",
    "r_ecef_dss13 = filter_functions.topo2ecef(lat_dss13, lon_dss13, alt_dss13, r_earth_const)\n",
    "#print(r_ecef_dss13)\n",
    "\n",
    "\n",
    "# read python dict containing measurements\n",
    "mydict2 = pickle.load(meas_file)\n",
    "meas_file.close()\n",
    "measurement_array = mydict2['measurement_array']\n",
    "truth_xyz = mydict2['truth_pos_vel']\n",
    "print(np.shape(measurement_array))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Propogate reference trajectory and S.T.M.\n",
    "def orbitpropogator_UKF(t, sigma_pt):\n",
    "    \n",
    "\n",
    "    density = calc_MSIS_density(t, sigma_pt)\n",
    "\n",
    "    #find X acceleration via the F(X) lambdified equation\n",
    "    state_acc = X_dot_sol_fcn(sigma_pt[0], sigma_pt[1], sigma_pt[2], \\\n",
    "                        sigma_pt[3], sigma_pt[4], sigma_pt[5], density).reshape(6,1)\n",
    "\n",
    "        \n",
    "    dx = state_acc.flatten()\n",
    "    return dx\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_MSIS_density(t, X_vector):\n",
    "    \n",
    "    state = X_vector[0:3] \n",
    "    \n",
    "    \n",
    "    day_of_year = math.floor(t/86400) + day_init\n",
    "    \n",
    "    #Calculations for theta_gmst (rotation btwn ECI & ECEF for the current time of simulation/orbit)--------------\n",
    "    hour = hour_init_UT + t/(60*60) #hours (float) since midnight UT\n",
    "    jd = filter_functions.calc_julian_date(year_init, month_init, day_init, hour) #date of interest in UT\n",
    "\n",
    "    T_UT = (jd - 2451545)/36525 #calc T_UT at this delta_t/date \n",
    "    #calculate theta gmst @ 0 hr using the T_UT and the eq. from Vallado \n",
    "    theta_gmst_0_hr = math.radians(100.4606184 + 36000.77005361*T_UT + \\\n",
    "                                           .00038793*T_UT**2 - 2.6e-8*T_UT**3)\n",
    "    seconds = hour * 60 * 60 #seconds since midnight UT \n",
    "    #calculate theta gmst using theta gmst @ 0 hr and seconds \n",
    "    #since midnight*the rotation rate of earth\n",
    "    theta_gmst = theta_gmst_0_hr + omega_const * seconds \n",
    "    theta_gmst = theta_gmst % (2*math.pi)\n",
    "\n",
    "\n",
    "    #calculate position in ECEF & then the lat/lon/alt-----------------------------------------------------------\n",
    "    r_ecef = filter_functions.eci2ecef(state, theta_gmst)\n",
    "    (latitude, longitude, altitude) = filter_functions.ecef2geo_lat_lon_alt(r_ecef, r_earth_const)\n",
    "    \n",
    "    \n",
    "    if longitude < 0:\n",
    "            longitude = longitude + 2*math.pi\n",
    "    lst = calc_LST(hour, longitude) #lst in units of radians\n",
    "    \n",
    "    lon = 0 #dependent only on lst\n",
    "\n",
    "\n",
    "    Output = nrlmsise_output()\n",
    "    Input = nrlmsise_input()\n",
    "    flags = nrlmsise_flags()\n",
    "    aph = ap_array()\n",
    "\n",
    "    for i in range(7):\n",
    "        aph.a[i]=100\n",
    "    flags.switches[0] = 1\n",
    "    for i in range(1, 24):\n",
    "        flags.switches[i]=1\n",
    "\n",
    "    Input.doy = day_of_year\n",
    "    Input.year = 0 #/* without effect */\n",
    "    Input.sec = t\n",
    "    Input.alt = altitude/1e3 #convert to km\n",
    "    Input.g_lat = math.degrees(latitude)\n",
    "    Input.g_long = math.degrees(lon)\n",
    "    Input.lst = lst\n",
    "    Input.f107A = 80 #I believe this is a \"nominal\" value\n",
    "    Input.f107 = 80\n",
    "    Input.ap = 4 \n",
    "\n",
    "    gtd7d(Input, flags, Output)\n",
    "\n",
    "    density = Output.d[5] #total mass density (grams/m^3, m^3 b/c switches[0] = 1)\n",
    "    \n",
    "    return density\n",
    "\n",
    "\n",
    "#t_UT : current universal time\n",
    "#current longitude of space object\n",
    "def calc_LST(t_UT, longitude):\n",
    "    \n",
    "    #calculate change in longitude from UT and convert to change in hours/time\n",
    "    #note: negative lon/lon above 180 is a negative difference in time & opposite for less than 180\n",
    "    delta_lon = 360 - np.degrees(longitude)\n",
    "    delta_lst = (delta_lon/360) * 24 #24 hours, unit = hours\n",
    "    \n",
    "    t_lst = t_UT - delta_lst \n",
    "    if t_lst < 0:\n",
    "        t_lst = t_lst + 24\n",
    "    \n",
    "    #return now if want in hours\n",
    "    \n",
    "    #convert to degrees\n",
    "    t_lst = (t_lst/24) * np.radians(360) #radians\n",
    "    \n",
    "    return t_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#two body motion force\n",
    "# **Setup force equations/acceleration/U\n",
    "\n",
    "#Force equations with J_2\n",
    "x, y, z, J_2, r_earth, mu, r, J_3 = sym.symbols('x y z J_2 r_earth mu r J_3')\n",
    "\n",
    "\n",
    "two_body_J2_string = 'mu/r * ( 1 - J_2*(r_earth/r)**2 * (3/2 * (z/r)**2 - 1/2) )'\n",
    "two_body_J2 = sym.sympify(two_body_J2_string)\n",
    "two_body_J2 = two_body_J2.subs([(r, sym.sqrt(x**2+y**2+z**2))])\n",
    "two_body_J2_acc_x = two_body_J2.diff(x)\n",
    "two_body_J2_acc_y = two_body_J2.diff(y)\n",
    "two_body_J2_acc_z = two_body_J2.diff(z)\n",
    "\n",
    "\n",
    "two_body_J2_acc_x = two_body_J2_acc_x.subs([(r_earth, r_earth_const), (mu, mu_earth), \\\n",
    "                              (J_2, J_2_const)])\n",
    "two_body_J2_acc_y = two_body_J2_acc_y.subs([(r_earth, r_earth_const), (mu, mu_earth), \\\n",
    "                              (J_2, J_2_const)])\n",
    "two_body_J2_acc_z = two_body_J2_acc_z.subs([(r_earth, r_earth_const), (mu, mu_earth), \\\n",
    "                              (J_2, J_2_const)])\n",
    "#print('2 body & J2', two_body_J2_acc_x)\n",
    "\n",
    "x_acc = two_body_J2_acc_x\n",
    "y_acc = two_body_J2_acc_y\n",
    "z_acc = two_body_J2_acc_z\n",
    "\n",
    "\n",
    "#Add drag to J_2 force equations\n",
    "\n",
    "x_dot, y_dot, z_dot, x_double_dot, y_double_dot, z_double_dot = \\\n",
    "    sym.symbols('x_dot, y_dot, z_dot, x_double_dot, y_double_dot, z_double_dot')\n",
    "    \n",
    "C_D, A, m, density, theta_dot, val, val_dot = \\\n",
    "    sym.symbols('C_D A m density theta_dot val, val_dot')\n",
    "\n",
    "drag_str = ('-(1/2)*C_D*(A/m)*density*'\n",
    "                'sqrt((x_dot+theta_dot*y)**2 + (y_dot-theta_dot*x)**2 +'\n",
    "                'z_dot**2)*(val_dot+theta_dot*val)')\n",
    "drag_symp = sym.sympify(drag_str)\n",
    "\n",
    "drag_symp = drag_symp.subs([(A, A_const), (m, m_const), (C_D, C_D_const),\\\n",
    "                        (theta_dot, theta_dot_const)])\n",
    "\n",
    "\n",
    "x_drag_symp = drag_symp.subs([(r, sym.sqrt(x**2+y**2+z**2)), (val, y), (val_dot, x_dot)])\n",
    "x_acc = x_acc + x_drag_symp\n",
    "\n",
    "y_drag_symp = drag_symp.subs([(r, sym.sqrt(x**2+y**2+z**2)), (val, x), (val_dot, y_dot)])\n",
    "y_acc = y_acc + y_drag_symp\n",
    "\n",
    "z_drag_symp = drag_symp.subs([(r, sym.sqrt(x**2+y**2+z**2)), (val, z), (val_dot, z_dot)])\n",
    "z_acc = z_acc + z_drag_symp\n",
    "    \n",
    "\n",
    "\n",
    "x_acc_sol_fcn = lambdify((x, y, z, x_dot, y_dot, z_dot, density), x_acc)\n",
    "y_acc_sol_fcn = lambdify((x, y, z, x_dot, y_dot, z_dot, density), y_acc)\n",
    "z_acc_sol_fcn = lambdify((x, y, z, x_dot, y_dot, z_dot, density), z_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if (meas_type == 1) or (meas_type == 3):\n",
    "    \n",
    "    x_s, y_s, z_s, x_sf, y_sf, z_sf, theta, theta_dot, t, x_dot, y_dot, z_dot = \\\n",
    "        sym.symbols('x_s, y_s, z_s, x_sf, y_sf, z_sf, theta, theta_dot, t, x_dot, y_dot, z_dot')\n",
    "\n",
    "    #define symbolic rho equation\n",
    "    rho = ('sqrt((x - x_s)**2 + (y - y_s)**2 + (z - z_s)**2)')\n",
    "    rho = sym.sympify(rho)\n",
    "    #sub rotation equation of ecef for eci\n",
    "    rho = rho.subs(x_s, x_sf*sym.cos(omega_const*t) - y_sf*sym.sin(omega_const*t))\n",
    "    rho = rho.subs(y_s, x_sf*sym.sin(omega_const*t) + y_sf*sym.cos(omega_const*t))\n",
    "    rho = rho.subs(z_s, z_sf)\n",
    "\n",
    "    #define symbolic rho dot equation\n",
    "    rho_dot = ('(x*x_dot + y*y_dot + z*z_dot - (x_dot*x_s+y_dot*y_s)*cos(theta) + \\\n",
    "               theta_dot*(x*x_s + y*y_s)*sin(theta) + (x_dot*y_s - y_dot*x_s)*sin(theta) +\\\n",
    "               theta_dot*(x*y_s - y*x_s)*cos(theta) - z_dot*z_s)/ rho')\n",
    "    rho_dot = sym.sympify(rho_dot)\n",
    "    #execute substitutions for rho_dot\n",
    "    rho_dot = rho_dot.subs(x_s, x_sf) \n",
    "    rho_dot = rho_dot.subs(y_s, y_sf) \n",
    "    rho_dot = rho_dot.subs(z_s, z_sf) \n",
    "    rho_dot = rho_dot.subs('rho', rho)\n",
    "    rho_dot = rho_dot.subs(theta, omega_const*t)    \n",
    "    rho_dot = rho_dot.subs(theta_dot, omega_const)\n",
    "\n",
    "    rho_fcn = lambdify(((x, y, z, x_sf, y_sf, z_sf, t)), rho)\n",
    "    rho_dot_fcn = lambdify(((x, y, z, x_dot, y_dot, z_dot, x_sf, y_sf, z_sf, t)), rho_dot)\n",
    "\n",
    "\n",
    "if (meas_type == 2) or (meas_type == 3):\n",
    "    \n",
    "    #x_sf, etc. is the sensor pos in ecef\n",
    "    #x, y, z is the satellite eci\n",
    "    x_s, y_s, z_s, x_sf, y_sf, z_sf, theta, x, y, z, t = \\\n",
    "        sym.symbols('x_s, y_s, z_s, x_sf, y_sf, z_sf, theta, x, y, z, t')\n",
    "    x_L, y_L, z_L, X_L_norm, x_range, y_range, z_range, lon, lat, \\\n",
    "        x_sat_ecef, y_sat_ecef, z_sat_ecef, sen_ecef_norm, omega  = \\\n",
    "        sym.symbols('x_L, y_L, z_L, X_L_norm, x_range, y_range, z_range, lon, lat, \\\n",
    "        x_sat_ecef, y_sat_ecef, z_sat_ecef, sen_ecef_norm, omega')\n",
    "        \n",
    "\n",
    "    #define symbolic rho equation\n",
    "    azimuth = ('atan2(x_L, y_L)') #step 4\n",
    "    azimuth = sym.sympify(azimuth)\n",
    "    \n",
    "    elevation = ('asin(z_L/X_L_norm)') #step 4\n",
    "    elevation = sym.sympify(elevation)\n",
    "    elevation = elevation.subs(X_L_norm, sym.sqrt(x_L**2 + y_L**2 + z_L**2))\n",
    "    \n",
    "    #step 3\n",
    "    azimuth = azimuth.subs([(x_L, -x_range*sym.sin(lon) + y_range*sym.cos(lon)), \\\n",
    "            (y_L, -x_range*sym.sin(lat)*sym.cos(lon) - y_range*sym.sin(lat)*sym.sin(lon) + z_range*sym.cos(lat))])\n",
    "    elevation = elevation.subs([(x_L, -x_range*sym.sin(lon) + y_range*sym.cos(lon)), \\\n",
    "            (y_L, -x_range*sym.sin(lat)*sym.cos(lon) - y_range*sym.sin(lat)*sym.sin(lon) + z_range*sym.cos(lat)), \\\n",
    "            (z_L, x_range*sym.cos(lat)*sym.cos(lon) + y_range*sym.cos(lat)*sym.sin(lon) + z_range*sym.sin(lat))])\n",
    "    \n",
    "    #step 2\n",
    "    azimuth = azimuth.subs([(x_range, x_sat_ecef - x_sf), (y_range, y_sat_ecef - y_sf), \\\n",
    "            (z_range, z_sat_ecef - z_sf), (lat, sym.asin(z_sf/sen_ecef_norm)), (lon, sym.atan2(y_sf, x_sf))])\n",
    "    elevation = elevation.subs([(x_range, x_sat_ecef - x_sf), (y_range, y_sat_ecef - y_sf), \\\n",
    "            (z_range, z_sat_ecef - z_sf), (lat, sym.asin(z_sf/sen_ecef_norm)), (lon, sym.atan2(y_sf, x_sf))])\n",
    "    \n",
    "    #step 1\n",
    "    azimuth = azimuth.subs([(x_sat_ecef, x*sym.cos(theta) + y*sym.sin(theta)), \\\n",
    "                        (y_sat_ecef, -x*sym.sin(theta) + y*sym.cos(theta)), (z_sat_ecef, z), \\\n",
    "                        (sen_ecef_norm, sym.sqrt(x_sf**2 + y_sf**2 + z_sf**2))])\n",
    "    elevation = elevation.subs([(x_sat_ecef, x*sym.cos(theta) + y*sym.sin(theta)), \\\n",
    "                        (y_sat_ecef, -x*sym.sin(theta) + y*sym.cos(theta)), (z_sat_ecef, z), \\\n",
    "                        (sen_ecef_norm, sym.sqrt(x_sf**2 + y_sf**2 + z_sf**2))])\n",
    "    \n",
    "    \n",
    "    azimuth = azimuth.subs([(theta, omega_const*t), (omega, omega_const)])\n",
    "    elevation = elevation.subs([(theta, omega_const*t), (omega, omega_const)])\n",
    "    \n",
    "    azimuth_fcn = lambdify(((x, y, z, x_sf, y_sf, z_sf, t)), azimuth)\n",
    "    elevation_fcn = lambdify(((x, y, z, x_sf, y_sf, z_sf, t)), elevation)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#State and A matrix\n",
    "\n",
    "\n",
    "#define the symbolic state matrix\n",
    "X = sym.Matrix([x, y, z, x_dot, y_dot, z_dot])\n",
    "X_dot = sym.Matrix([x_dot, y_dot, z_dot, x_acc, y_acc, z_acc])\n",
    "    \n",
    "\n",
    "#partial of the force model (x dot) WRT the state vector\n",
    "A_mat = X_dot.jacobian(X)\n",
    "#print(A_mat)\n",
    "\n",
    "A_sol_fcn = lambdify((x, y, z, x_dot, y_dot, z_dot, density), A_mat)\n",
    "#print(A_sol_fcn(1,2,3,4,5,6,7,8))\n",
    "\n",
    "#print(X_dot)\n",
    "X_dot_sol_fcn = lambdify((x, y, z, x_dot, y_dot, z_dot, density), X_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define observation model (G) and H_tilde\n",
    "\n",
    "\n",
    "if meas_type == 1:\n",
    "    G = sym.Matrix([rho, rho_dot])\n",
    "    \n",
    "    \n",
    "elif meas_type == 2:\n",
    "    G = sym.Matrix([azimuth, elevation])\n",
    "    \n",
    "elif meas_type == 3:\n",
    "    G = sym.Matrix([azimuth, elevation, rho])\n",
    "\n",
    "#print(G)\n",
    "G_sol_fcn = lambdify((x, y, z, x_dot, y_dot, z_dot, x_sf, y_sf, z_sf, t), G)\n",
    "\n",
    "#partial derivitive of observation model WRT the state vector\n",
    "H_tilde = G.jacobian(X)\n",
    "#print(H_tilde)\n",
    "H_tilde_sol_fcn = lambdify((x, y, z, x_dot, y_dot, z_dot, x_sf, y_sf, z_sf, t), H_tilde)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unscented Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initilaizations\n",
    "\n",
    "alpha = 5e-4\n",
    "beta = 2\n",
    "\n",
    "L = 6 #number of states\n",
    "k = 3-L\n",
    "lambdaa = alpha**2*(L + k) - L\n",
    "gamma = math.sqrt(L+lambdaa)#alpha*math.sqrt(3)\n",
    "\n",
    "\n",
    "#weights\n",
    "weights_m_0 = lambdaa/(L+lambdaa)\n",
    "weights_c_0 = lambdaa/(L+lambdaa) + (1-alpha**2+beta)\n",
    "\n",
    "weights_m_1 = 1/(2*(L+lambdaa))\n",
    "weights_c_1 = 1/(2*(L+lambdaa))\n",
    "\n",
    "pos_perturbation = 100\n",
    "vel_perturbation = .1\n",
    "\n",
    "#state \n",
    "X_ref = np.array([truth_xyz[0,0] + pos_perturbation, truth_xyz[0,1] + pos_perturbation, truth_xyz[0,2] \\\n",
    "            + pos_perturbation, truth_xyz[0,3] + vel_perturbation, truth_xyz[0,4] + vel_perturbation, \\\n",
    "            truth_xyz[0,5] + vel_perturbation]).reshape(L,1)\n",
    "\n",
    "\n",
    "x_bar_0 = np.zeros((6,1))\n",
    "\n",
    "P_sigma_pos = 100\n",
    "P_sigma_vel = .1\n",
    "P_bar_0 = np.diag([P_sigma_pos**2, P_sigma_pos**2, P_sigma_pos**2, \\\n",
    "                   P_sigma_vel**2, P_sigma_vel**2, P_sigma_vel**2])\n",
    "\n",
    "                  \n",
    "#Define Measurement Noise\n",
    "if meas_type == 1:\n",
    "    sigma_rho = .1 \n",
    "    sigma_rho_dot = .01\n",
    "    W = np.array([[1/sigma_rho**2, 0], [0, 1/sigma_rho_dot**2]])\n",
    "    R = np.linalg.inv(W)\n",
    "    \n",
    "elif meas_type == 2:\n",
    "    arcsec_per_rad = 206264.806247 #arcsec/rad\n",
    "    noise_rad = (1/arcsec_per_rad)  * 5  #5 arcsec noise (suggested by Moriba for a telescope)\n",
    "    sigma_az = noise_rad\n",
    "    sigma_el = noise_rad\n",
    "    W = np.array([[1/sigma_az**2, 0], [0, 1/sigma_el**2]])\n",
    "    R = np.linalg.inv(W)\n",
    "    \n",
    "elif meas_type == 3:\n",
    "    arcsec_per_rad = 206264.806247 #arcsec/rad\n",
    "    noise_rad = (1/arcsec_per_rad)  * 5  #5 arcsec noise (suggested by Moriba for a telescope)\n",
    "    sigma_az = noise_rad\n",
    "    sigma_el = noise_rad\n",
    "    sigma_rho = .1 \n",
    "    W = np.array([[1/sigma_az**2, 0, 0], [0, 1/sigma_el**2, 0], [0, 0, 1/sigma_rho**2]])\n",
    "    R = np.linalg.inv(W)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_sigma_points(sigma_point, P_bar, gamma, L):\n",
    "    sigma_point = sigma_point.reshape(6,1)\n",
    "    center_x_hat = sigma_point\n",
    "    x_hat_tiled = np.tile(sigma_point, L)\n",
    "    right_x_hat = x_hat_tiled + gamma*scipy.linalg.sqrtm(P_bar)\n",
    "    left_x_hat = x_hat_tiled - gamma*scipy.linalg.sqrtm(P_bar)\n",
    "    \n",
    "    sigma_points = np.array([])\n",
    "\n",
    "    #build sigma point (comprised of matrices built above)\n",
    "    sigma_points = np.append(sigma_points, center_x_hat)\n",
    "    sigma_points = np.append(sigma_points, right_x_hat.T)\n",
    "    sigma_points = np.append(sigma_points, left_x_hat.T)\n",
    "    \n",
    "    return sigma_points\n",
    "\n",
    "sigma_points_0 = compute_sigma_points(X_ref, P_bar_0, gamma, L)\n",
    "\n",
    "\n",
    "def calc_sigma_pt_TU(weight_0, weight_1, sigma_points, L):\n",
    "    \n",
    "    num_of_pts = 2*L+1\n",
    "    sigma_points = sigma_points.reshape(num_of_pts, L).T\n",
    "    #print(sigma_points[:, 0])\n",
    "    sigma_pt = np.zeros((L, 1))\n",
    "\n",
    "    for i in range(num_of_pts):\n",
    "        if i == 0:\n",
    "            weighted_pt = weight_0*sigma_points[:, i].reshape(6,1)\n",
    "        else:\n",
    "            weighted_pt = weight_1*sigma_points[:, i].reshape(6,1)\n",
    "        \n",
    "        sigma_pt = sigma_pt + weighted_pt\n",
    "    \n",
    "    return sigma_pt\n",
    "\n",
    "\n",
    "\n",
    "def calc_P_bar_TU(weight_0, weight_1, sigma_pt, sigma_points, L):\n",
    "    \n",
    "    num_of_pts = 2*L+1\n",
    "    sigma_points = sigma_points.reshape(num_of_pts, L).T\n",
    "\n",
    "    P_bar = np.zeros((L, L))\n",
    "    \n",
    "    \n",
    "    for i in range(num_of_pts):\n",
    "\n",
    "        difference = sigma_points[:, i].reshape(6,1) - sigma_pt.reshape(6, 1)\n",
    "        \n",
    "        if i ==0 :\n",
    "            weighted_covar = weight_0*difference*difference.T\n",
    "        else:\n",
    "            weighted_covar = weight_1*difference*difference.T\n",
    "            \n",
    "        #print(weighted_covar)\n",
    "        P_bar = P_bar + weighted_covar\n",
    "\n",
    "    \n",
    "    return P_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_measurements(sigma_points, X_s, time):\n",
    "    \n",
    "    num_of_pts = 2*L+1\n",
    "    sigma_points = sigma_points.reshape(num_of_pts, L).T\n",
    "    Y_mat = np.zeros((num_of_meas, num_of_pts))\n",
    "    \n",
    "    for i in range(num_of_pts):\n",
    "\n",
    "        sigma_pt = sigma_points[:, i]\n",
    "        \n",
    "        Y = G_sol_fcn(*sigma_pt, *X_s, time)\n",
    "        Y = Y.reshape(num_of_meas)\n",
    "        \n",
    "        if meas_type != 1:\n",
    "            if Y[0,0] < 0:\n",
    "                Y[0,0] = Y[0,0] + 2*math.pi\n",
    "        \n",
    "        Y_mat[:, i] = Y\n",
    "    \n",
    "    return Y_mat\n",
    "\n",
    "def compute_y_bar(weight_0, weight_1, Y_mat, L):\n",
    "\n",
    "    num_of_pts = 2*L+1\n",
    "    y_bar = np.zeros((num_of_meas, 1))\n",
    "    \n",
    "    for i in range(num_of_pts):\n",
    "        if i == 0:\n",
    "            weighted_Y = weight_0*Y_mat[:, i].reshape(num_of_meas,1)\n",
    "        else:\n",
    "            weighted_Y = weight_1*Y_mat[:, i].reshape(num_of_meas,1)\n",
    "            \n",
    "        y_bar = y_bar + weighted_Y\n",
    "\n",
    "    return y_bar\n",
    "    \n",
    "\n",
    "\n",
    "def calc_Pyy(weight_0, weight_1, Y_mat, y_bar, L):\n",
    "    \n",
    "    num_of_pts = 2*L+1\n",
    "    Pyy = np.zeros((num_of_meas, num_of_meas))\n",
    "    \n",
    "    for i in range(num_of_pts):\n",
    "\n",
    "        difference = Y_mat[:, i].reshape(num_of_meas,1) - y_bar.reshape(num_of_meas, 1)\n",
    "        #print(difference)\n",
    "        \n",
    "        if i ==0 :\n",
    "            weighted_pyy = weight_0*np.dot(difference, difference.T)\n",
    "        else:\n",
    "            weighted_pyy = weight_1*np.dot(difference, difference.T)\n",
    "            \n",
    "        Pyy = Pyy + weighted_pyy\n",
    "\n",
    "    return Pyy\n",
    "\n",
    "\n",
    "def calc_Pxy(weight_0, weight_1, Y_mat, y_bar, sigma_pt, sigma_points, L):\n",
    "    \n",
    "    num_of_pts = 2*L+1\n",
    "    Pxy = np.zeros((L, num_of_meas))\n",
    "    sigma_points = sigma_points.reshape(num_of_pts, L).T\n",
    "    \n",
    "    for i in range(num_of_pts):\n",
    "        \n",
    "        y_difference = Y_mat[:, i].reshape(num_of_meas,1) - y_bar.reshape(num_of_meas, 1)\n",
    "        x_difference = sigma_points[:, i].reshape(L,1) - sigma_pt.reshape(L, 1)\n",
    "        \n",
    "        if i ==0 :\n",
    "            weighted_xy = weight_0*np.dot(x_difference, y_difference.T)\n",
    "        else:\n",
    "            weighted_xy = weight_1*np.dot(x_difference, y_difference.T)\n",
    "            \n",
    "        Pxy = Pxy + weighted_xy\n",
    "\n",
    "    return Pxy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unscented KF\n",
    "\n",
    "def execute_ukf(obs_data, sigma_points, X_ref, P_bar_0, prob_dimension, snc_sigma, snc_flag, gamma):\n",
    "\n",
    "    \n",
    "    #initializations\n",
    "    P = P_bar_0\n",
    "    x_hat = X_ref.reshape(prob_dimension,1)\n",
    "\n",
    "    P_list = np.array([])\n",
    "    x_hat_array = np.array([])\n",
    "    Pyy_array = np.array([])\n",
    "    Pxy_array = np.array([])\n",
    "    post_fit_list = np.array([])\n",
    "    \n",
    "    #Covariance with SNC: Q Matrix\n",
    "    Q = np.identity(3)*(snc_sigma)**2\n",
    "    snc_stm = np.zeros((6,3))\n",
    "    \n",
    "    \n",
    "    #begin UKF\n",
    "    for obsnum in range(len(obs_data)):#len(obs_data)):\n",
    "        time = obs_data[obsnum, 0]\n",
    "        t_init = obs_data[obsnum-1, 0]\n",
    "        \n",
    "        print(obsnum)\n",
    "        \n",
    "        #set the initial values for the propogator:\n",
    "        y0 = sigma_points.flatten()\n",
    "        \n",
    " \n",
    "        if (obs_data[obsnum, 0] != obs_data[obsnum-1, 0]) and obsnum != 0:\n",
    "            \n",
    "            result = np.zeros((2*L+1, prob_dimension))\n",
    "            sigma_points = sigma_points.reshape(2*L+1, prob_dimension)\n",
    "\n",
    "            for ii in range(2*L+1):\n",
    "                \n",
    "                y0 = sigma_points[ii, :]\n",
    "            \n",
    "                integrator = ode(orbitpropogator_UKF)\n",
    "                integrator.set_integrator('dopri5', nsteps=1e6, rtol=1e-12, atol=1e-12)\n",
    "\n",
    "                integrator.set_initial_value(y0, t_init)\n",
    "                integrator.integrate(time)\n",
    "                result[ii, :] = np.array(integrator.y)\n",
    "   \n",
    "            sigma_points = result.flatten()\n",
    "        \n",
    "\n",
    "        #Time Update- only if measurement is at different time than last measurement\n",
    "        if (obs_data[obsnum, 0] != obs_data[obsnum-1, 0]) and (obsnum != 0):\n",
    "            sigma_point_TU = calc_sigma_pt_TU(weights_m_0, weights_m_1, sigma_points, L)\n",
    "            P_bar_TU = calc_P_bar_TU(weights_c_0, weights_c_1, sigma_point_TU, sigma_points, L)\n",
    "\n",
    "            \n",
    "            #Use SNC P_bar if delta t is less than 100 seconds---------------------------\n",
    "            delta_t = obs_data[obsnum, 0] - obs_data[obsnum-1, 0]\n",
    "            if obsnum == 0:\n",
    "                delta_t = 0\n",
    "            if (delta_t < 15 and snc_flag == True):\n",
    "                #build SNC STM\n",
    "                idenity_6_3 = np.array([(delta_t/2)*np.eye(3), np.eye(3)]).reshape(6, 3)\n",
    "                snc_stm = delta_t*idenity_6_3\n",
    "                #Covariance with SNC: Q Matrix\n",
    "                Q = np.identity(3)*(snc_sigma)**2\n",
    "                P_bar_TU = np.dot(snc_stm, np.dot(Q, snc_stm.T)) + P_bar_TU\n",
    "            else:\n",
    "                #don't add SNC, so set Q to zeros\n",
    "                Q = np.zeros((3,3))\n",
    "            \n",
    "            #recompute sigma points\n",
    "            #sigma_points = compute_sigma_points(sigma_point_TU, P_bar_TU, gamma, L) #sqrtm(Pbar_TU) @ 200 = imaginary\n",
    "            \n",
    "        else:\n",
    "            sigma_point_TU = x_hat\n",
    "            P_bar_TU = P\n",
    "            \n",
    "\n",
    "        #determine station coordinates for observation eq.\n",
    "        if int(obs_data[obsnum, 1]) == 1:\n",
    "            #print('35')\n",
    "            X_s = r_ecef_dss34\n",
    "        if int(obs_data[obsnum, 1]) == 2:\n",
    "            #print('65')\n",
    "            X_s = r_ecef_dss65\n",
    "        if int(obs_data[obsnum, 1]) == 3:\n",
    "            #print('13')\n",
    "            X_s = r_ecef_dss13\n",
    "            #Tracer() ()\n",
    "            \n",
    "            \n",
    "        \n",
    "        #compute measurements & weighted average\n",
    "        Y_mat = compute_measurements(sigma_points, X_s, time)\n",
    "        #print(Y_mat)\n",
    "        y_bar = compute_y_bar(weights_m_0, weights_m_1, Y_mat, L)\n",
    "        #print(y_bar)\n",
    "        \n",
    "\n",
    "        #Innovation & Cross-Correlation\n",
    "        Pyy_term = calc_Pyy(weights_c_0, weights_c_1, Y_mat, y_bar, L)\n",
    "        Pyy = R + Pyy_term\n",
    "        #print(R)\n",
    "        #print(Pyy_term)\n",
    "        Pxy = calc_Pxy(weights_c_0, weights_c_1, Y_mat, y_bar, sigma_point_TU, sigma_points, L)\n",
    "        #print(Pxy)\n",
    "\n",
    "        #Measurement Update\n",
    "        K = np.dot(Pxy, np.linalg.inv(Pyy))\n",
    "        #print(K)\n",
    "        Y_observed = obs_data[obsnum, 2:(2+num_of_meas)].reshape(num_of_meas,1)\n",
    "        x_hat = sigma_point_TU + np.dot(K, (Y_observed - y_bar))\n",
    "        #print(x_hat)\n",
    "        #print(Y_observed - y_bar)\n",
    "        P = P_bar_TU - np.dot(K, np.dot(Pyy, K.T))\n",
    "\n",
    "        #recompute sigma points\n",
    "        sigma_points = compute_sigma_points(x_hat, P, gamma, L)\n",
    "        \n",
    "        \n",
    "        Y = G_sol_fcn(*x_hat, *X_s, time)\n",
    "        if meas_type != 1:\n",
    "            if Y[0,0] < 0:\n",
    "                Y[0,0] = Y[0,0] + 2* math.pi\n",
    "        post_fit_resid = Y_observed - Y\n",
    "\n",
    "        \n",
    "        \n",
    "        x_hat_array = np.append(x_hat_array, x_hat.reshape(prob_dimension,1))\n",
    "        P_list = np.append(P_list, P)\n",
    "        Pyy_array = np.append(Pyy_array, Pyy)\n",
    "        Pxy_array = np.append(Pxy_array, Pxy)\n",
    "        post_fit_list = np.append(post_fit_list, post_fit_resid)  \n",
    "\n",
    "\n",
    "\n",
    "    #resize arrays\n",
    "    n = len(obs_data)\n",
    "    P_list.shape = (n, prob_dimension, prob_dimension)\n",
    "    x_hat_array.shape = (n, prob_dimension)\n",
    "    Pyy_array.shape = (n, num_of_meas, num_of_meas)\n",
    "    Pxy_array.shape = (n, prob_dimension, num_of_meas)\n",
    "    post_fit_list.shape = (n, num_of_meas)\n",
    "\n",
    "    \n",
    "    return (x_hat_array, P_list, Pyy_array, Pxy_array, post_fit_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n"
     ]
    }
   ],
   "source": [
    "prob_dimension = 6\n",
    "snc_sigma = 1e-8\n",
    "snc_flag = True\n",
    "\n",
    "(x_hat_array_ukf, P_list_ukf, Pyy_array_ukf, Pxy_array_ukf, post_fit_list_ukf) = \\\n",
    "        execute_ukf(measurement_array, sigma_points_0, X_ref, P_bar_0, prob_dimension, \\\n",
    "                    snc_sigma, snc_flag, gamma)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4.449499494785039e+06   3.888849001652403e+06   3.313311449784491e+06\n",
      "  -5.788075686515190e+03   3.890032367467731e+03   3.191832727067075e+03]\n",
      "[[  4.449599494785039e+06]\n",
      " [  3.888949001652403e+06]\n",
      " [  3.313411449784491e+06]\n",
      " [ -5.787975686515189e+03]\n",
      " [  3.890132367467731e+03]\n",
      " [  3.191932727067075e+03]]\n"
     ]
    }
   ],
   "source": [
    "print(truth_xyz[0, :])\n",
    "print(X_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'post_fit_list_ukf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-daba6860c1bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mstop_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeasurement_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcalc_display_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost_fit_list_ukf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasurement_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeas_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplot_error_covar_xref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP_list_ukf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_hat_array_ukf\u001b[0m\u001b[0;34m,\u001b[0m                       \u001b[0mtruth_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasurement_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'post_fit_list_ukf' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x_range = 5\n",
    "y_range = 5\n",
    "z_range = 5\n",
    "\n",
    "\n",
    "times = measurement_array[:, 0]\n",
    "stop_index = len(measurement_array)\n",
    "\n",
    "calc_display_results(post_fit_list_ukf, measurement_array, meas_type, stop_index)\n",
    "\n",
    "plot_error_covar_xref(P_list_ukf, x_hat_array_ukf, \\\n",
    "                      truth_xyz, x_range, y_range, z_range, measurement_array, times, stop_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_display_results(post_fit_list, measurement_array, meas_type, stop_index):\n",
    "    \n",
    "    \n",
    "    rms_1 = 'Range ='\n",
    "    unit_1 = 'meters'\n",
    "    ylabel_1 = 'Range Residuals (meters)'\n",
    "    title_1 = 'Range Post-fit Residuals'\n",
    "    save_fig_1 = 'postfit_range.png'\n",
    "    rms_2 = 'Range Rate ='\n",
    "    unit_2 = 'm/s'\n",
    "    ylabel_2 = 'Range Rate Residuals (m/s)'\n",
    "    title_2 = 'Range Rate Post-fit Residuals'\n",
    "    save_fig_2 = 'postfit_rangeRate.png'\n",
    "    post_fit_list_new = copy.deepcopy(post_fit_list)\n",
    "         \n",
    "    if (meas_type == 2) or (meas_type == 3):\n",
    "        rms_1 = 'Azimuth ='\n",
    "        unit_1 = 'degrees'\n",
    "        rms_2 = 'Elevation ='\n",
    "        unit_2 = 'degrees'\n",
    "        post_fit_list_new[:, 0] = np.degrees(post_fit_list[:, 0])\n",
    "        post_fit_list_new[:, 1] = np.degrees(post_fit_list[:, 1])\n",
    "        ylabel_1 = 'Azimuth Residuals (degrees)'\n",
    "        title_1 = 'Azimuth Post-fit Residuals'\n",
    "        save_fig_1 = 'postfit_az.png'\n",
    "        ylabel_2 = 'Elevation Residuals (degrees)'\n",
    "        title_2 = 'Elevation Post-fit Residuals'\n",
    "        save_fig_2 = 'postfit_el_rate.png'\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "    times = measurement_array[:stop_index,0]/(60*60)\n",
    "    \n",
    "    indices_1 = np.where(measurement_array[:stop_index, 1] == 1)[0]\n",
    "    indices_2 = np.where(measurement_array[:stop_index, 1] == 2)[0]\n",
    "    indices_3 = np.where(measurement_array[:stop_index, 1] == 3)[0]\n",
    "\n",
    "    \n",
    "    \n",
    "    #Post-fit\n",
    "    print('Post-fit RMS:')\n",
    "    post_fit_1_list_4RMS = post_fit_list_new[:, 0]\n",
    "    postfit_1_rms = np.sqrt(np.mean(np.square(post_fit_1_list_4RMS)))\n",
    "    print(rms_1, postfit_1_rms, unit_1)\n",
    "\n",
    "    post_fit_2_list_4RMS = post_fit_list_new[:, 1]\n",
    "    postfit_2_rms = np.sqrt(np.mean(np.square(post_fit_2_list_4RMS)))\n",
    "    print(rms_2, postfit_2_rms, unit_2)\n",
    "    \n",
    "    if meas_type == 3:\n",
    "        post_fit_3_list_4RMS = post_fit_list_new[:, 2]\n",
    "        postfit_3_rms = np.sqrt(np.mean(np.square(post_fit_3_list_4RMS)))\n",
    "        print('Range =', postfit_3_rms, 'meters')\n",
    "    \n",
    "    \n",
    "\n",
    "   \n",
    "    #Post-fit Residuals\n",
    "    fig = plt.figure()\n",
    "    plt.scatter(times[indices_1], post_fit_list_new[indices_1, 0], s=70, c='g', marker='x')\n",
    "    plt.scatter(times[indices_2], post_fit_list_new[indices_2, 0], s=70, c='b', marker='+')\n",
    "    plt.scatter(times[indices_3], post_fit_list_new[indices_3, 0], s=70, c='m', marker='*')\n",
    "    #plt.scatter(times, post_fit_list[:, 0])\n",
    "    plt.ylabel(ylabel_1, fontsize=18)\n",
    "    plt.xlabel('Time (hours)', fontsize=18)\n",
    "    plt.title(title_1, fontsize=18)\n",
    "    legend_names = ['Station 1', 'Station 2', 'Station 3']\n",
    "    plt.legend(legend_names, fontsize=16)\n",
    "    #plt.ylim([-.01,.01])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #fig.savefig(save_fig_1)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.scatter(times[indices_1], post_fit_list_new[indices_1, 1], s=70, c='g', marker='x')\n",
    "    plt.scatter(times[indices_2], post_fit_list_new[indices_2, 1], s=70, c='b', marker='+')\n",
    "    plt.scatter(times[indices_3], post_fit_list_new[indices_3, 1], s=70, c='m', marker='*')\n",
    "    #plt.scatter(times, post_fit_list[:, 1])\n",
    "    plt.ylabel(ylabel_2, fontsize=18)\n",
    "    plt.xlabel('Time (hours)', fontsize=18)\n",
    "    plt.title(title_2, fontsize=18)\n",
    "    legend_names = ['Station 1', 'Station 2', 'Station 3']\n",
    "    plt.legend(legend_names, fontsize=16)\n",
    "    #plt.ylim([-.01,.01])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #fig.savefig(save_fig_2)\n",
    "    \n",
    "    if meas_type == 3:\n",
    "        fig = plt.figure()\n",
    "        plt.scatter(times[indices_1], post_fit_list_new[indices_1, 2], s=70, c='g', marker='x')\n",
    "        plt.scatter(times[indices_2], post_fit_list_new[indices_2, 2], s=70, c='b', marker='+')\n",
    "        plt.scatter(times[indices_3], post_fit_list_new[indices_3, 2], s=70, c='m', marker='*')\n",
    "        #plt.scatter(times, post_fit_list[:, 1])\n",
    "        plt.ylabel('Range Residuals (meters)', fontsize=18)\n",
    "        plt.xlabel('Time (days)', fontsize=18)\n",
    "        plt.title('Range Post-fit Residuals', fontsize=18)\n",
    "        legend_names = ['Station 1', 'Station 2', 'Station 3']\n",
    "        plt.legend(legend_names, fontsize=16)\n",
    "        #plt.ylim([-.01,.01])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        #fig.savefig('postfit_range.png')\n",
    "    \n",
    "    \n",
    "    \n",
    "def plot_error_covar_xref(P_list, x_ref_updated_list, obs_data_truth, x_range, \\\n",
    "                          y_range, z_range, measurement_array, time, stop_index):\n",
    "    \n",
    "    #Compare to the Truth Data : Estimation Errors------\n",
    "\n",
    "    times = time[:stop_index]/(60*60)\n",
    "    \n",
    "    indices_1 = np.where(measurement_array[:stop_index, 1] == 1)[0]\n",
    "    indices_2 = np.where(measurement_array[:stop_index, 1] == 2)[0]\n",
    "    indices_3 = np.where(measurement_array[:stop_index, 1] == 3)[0]\n",
    "    \n",
    "    \n",
    "    x_covar_env_upper = np.sqrt(abs(P_list[:stop_index, 0, 0]))*3\n",
    "    x_covar_env_lower = -np.sqrt(abs(P_list[:stop_index, 0, 0]))*3\n",
    "    x_error = x_ref_updated_list[:,0] - obs_data_truth[:stop_index, 0]\n",
    "    \n",
    "    y_covar_env_upper = np.sqrt(abs(P_list[:stop_index, 1, 1]))*3\n",
    "    y_covar_env_lower = -np.sqrt(abs(P_list[:stop_index, 1, 1]))*3\n",
    "    y_error = x_ref_updated_list[:,1] - obs_data_truth[:stop_index, 1]\n",
    "    \n",
    "    z_covar_env_upper = np.sqrt(abs(P_list[:stop_index, 2, 2]))*3\n",
    "    z_covar_env_lower = -np.sqrt(abs(P_list[:stop_index, 2, 2]))*3\n",
    "    z_error = x_ref_updated_list[:,2] - obs_data_truth[:stop_index, 2]\n",
    "    \n",
    "    #error_pos_norm = np.sqrt(x_error**2 + y_error**2 + z_error**2)\n",
    "    print('Position RMS:')\n",
    "    error_x_pos_rms_3D = np.sqrt(np.mean(np.square(x_error)))\n",
    "    print('X =', error_x_pos_rms_3D, 'meters')\n",
    "    \n",
    "    error_y_pos_rms_3D = np.sqrt(np.mean(np.square(y_error)))\n",
    "    print('Y =', error_y_pos_rms_3D, 'meters')\n",
    "    \n",
    "    error_z_pos_rms_3D = np.sqrt(np.mean(np.square(z_error)))\n",
    "    print('Z =', error_z_pos_rms_3D, 'meters')\n",
    "    \n",
    "    pos_rms = np.sqrt(error_x_pos_rms_3D**2 + error_y_pos_rms_3D**2 + error_z_pos_rms_3D**2)\n",
    "    print('Overall =', pos_rms/1e3, 'km')\n",
    "    \n",
    "\n",
    "    #x Position\n",
    "    fig = plt.figure()\n",
    "    plt.plot(times, x_covar_env_upper, label='_nolegend_')\n",
    "    plt.plot(times, x_covar_env_lower, label='_nolegend_')\n",
    "    plt.scatter(times[indices_1], x_error[indices_1], s=70, c='g', marker='x')\n",
    "    plt.scatter(times[indices_2], x_error[indices_2], s=70, c='b', marker='+')\n",
    "    plt.scatter(times[indices_3], x_error[indices_3], s=70, c='m', marker='*')\n",
    "    #plt.scatter(times, x_error)\n",
    "    plt.ylabel('meters', fontsize=18)\n",
    "    plt.xlabel('Time (hours)', fontsize=18)\n",
    "    legend_names = ['Station 1', 'Station 2', 'Station 3']\n",
    "    plt.legend(legend_names, fontsize=16)\n",
    "    plt.title('UKF X Position Covariance Envelope', fontsize=18)\n",
    "    plt.ylim([-x_range,x_range])\n",
    "    #plt.xlim([0,time_hrs[-1]])\n",
    "    plt.show()\n",
    "    #fig.savefig('x_pos_error.png')\n",
    "\n",
    "    #y Position \n",
    "    fig = plt.figure()\n",
    "    plt.plot(times, y_covar_env_upper, label='_nolegend_')\n",
    "    plt.plot(times, y_covar_env_lower, label='_nolegend_')\n",
    "    plt.scatter(times[indices_1], y_error[indices_1], s=70, c='g', marker='x')\n",
    "    plt.scatter(times[indices_2], y_error[indices_2], s=70, c='b', marker='+')\n",
    "    plt.scatter(times[indices_3], y_error[indices_3], s=70, c='m', marker='*')\n",
    "    #plt.scatter(times, y_error)\n",
    "    plt.ylabel('meters', fontsize=18)\n",
    "    plt.xlabel('Time (hours)', fontsize=18)\n",
    "    plt.legend(legend_names, fontsize=16)\n",
    "    plt.title('UKF Y Position Covariance Envelope', fontsize=18)\n",
    "    plt.ylim([-y_range,y_range])\n",
    "    #plt.xlim([0,time_hrs[-1]])\n",
    "    plt.show()\n",
    "    #fig.savefig('y_pos_error.png')\n",
    "\n",
    "    #z Position\n",
    "    fig = plt.figure()\n",
    "    plt.plot(times, z_covar_env_upper, label='_nolegend_')\n",
    "    plt.plot(times, z_covar_env_lower, label='_nolegend_')\n",
    "    plt.scatter(times[indices_1], z_error[indices_1], s=70, c='g', marker='x')\n",
    "    plt.scatter(times[indices_2], z_error[indices_2], s=70, c='b', marker='+')\n",
    "    plt.scatter(times[indices_3], z_error[indices_3], s=70, c='m', marker='*')\n",
    "    #plt.scatter(times, z_error)\n",
    "    plt.ylabel('meters', fontsize=18)\n",
    "    plt.xlabel('Time (hours)', fontsize=18)\n",
    "    plt.legend(legend_names, fontsize=16)\n",
    "    plt.title('UKF Z Position Covariance Envelope', fontsize=18)\n",
    "    plt.ylim([-z_range,z_range])\n",
    "    #plt.xlim([0,time_hrs[-1]])\n",
    "    plt.show()\n",
    "    #fig.savefig('z_pos_error.png')\n",
    "    \n",
    "    #x Velocity\n",
    "    x_dot_covar_env_upper = np.sqrt(abs(P_list[:stop_index, 3, 3]))*3\n",
    "    x_dot_covar_env_lower = -np.sqrt(abs(P_list[:stop_index, 3, 3]))*3\n",
    "    x_vel_error = x_ref_updated_list[:,3] - obs_data_truth[:stop_index, 3]\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.plot(times, x_dot_covar_env_upper, label='_nolegend_')\n",
    "    plt.plot(times, x_dot_covar_env_lower, label='_nolegend_')\n",
    "    plt.scatter(times[indices_1], x_vel_error[indices_1], s=70, c='g', marker='x')\n",
    "    plt.scatter(times[indices_2], x_vel_error[indices_2], s=70, c='b', marker='+')\n",
    "    plt.scatter(times[indices_3], x_vel_error[indices_3], s=70, c='m', marker='*')\n",
    "    #plt.scatter(times, x_vel_error)\n",
    "    plt.ylabel('meters/second', fontsize=18)\n",
    "    plt.xlabel('Time (hours)', fontsize=18)\n",
    "    plt.legend(legend_names, fontsize=16)\n",
    "    plt.title('UKF X Velocity Estimation Covariance Envelope', fontsize=18)\n",
    "    #plt.ylim([-x_range,x_range])\n",
    "    #plt.xlim([0,time_hrs[-1]])\n",
    "    plt.show()\n",
    "    #fig.savefig('x_vel_error.png')\n",
    "\n",
    "    #y Velocity\n",
    "    y_dot_covar_env_upper = np.sqrt(abs(P_list[:stop_index, 4, 4]))*3\n",
    "    y_dot_covar_env_lower = -np.sqrt(abs(P_list[:stop_index, 4, 4]))*3\n",
    "    y_vel_error = x_ref_updated_list[:,4] - obs_data_truth[:stop_index, 4]\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.plot(times, y_dot_covar_env_upper, label='_nolegend_')\n",
    "    plt.plot(times, y_dot_covar_env_lower, label='_nolegend_')\n",
    "    plt.scatter(times[indices_1], y_vel_error[indices_1], s=70, c='g', marker='x')\n",
    "    plt.scatter(times[indices_2], y_vel_error[indices_2], s=70, c='b', marker='+')\n",
    "    plt.scatter(times[indices_3], y_vel_error[indices_3], s=70, c='m', marker='*')\n",
    "    #plt.scatter(times, y_vel_error)\n",
    "    plt.ylabel('meters/second', fontsize=18)\n",
    "    plt.xlabel('Time (hours)', fontsize=18)\n",
    "    plt.legend(legend_names, fontsize=16)\n",
    "    plt.title('UKF Y Velocity Estimation Covariance Envelope', fontsize=18)\n",
    "    #plt.ylim([-y_range,y_range])\n",
    "    #plt.xlim([0,time_hrs[-1]])\n",
    "    plt.show()\n",
    "    #fig.savefig('y_vel_error.png')\n",
    "\n",
    "    #z Velocity\n",
    "    z_dot_covar_env_upper = np.sqrt(abs(P_list[:stop_index, 5, 5]))*3\n",
    "    z_dot_covar_env_lower = -np.sqrt(abs(P_list[:stop_index, 5, 5]))*3\n",
    "    z_vel_error = x_ref_updated_list[:,5] - obs_data_truth[:stop_index, 5]\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.plot(times, z_dot_covar_env_upper, label='_nolegend_')\n",
    "    plt.plot(times, z_dot_covar_env_lower, label='_nolegend_')\n",
    "    plt.scatter(times[indices_1], z_vel_error[indices_1], s=70, c='g', marker='x')\n",
    "    plt.scatter(times[indices_2], z_vel_error[indices_2], s=70, c='b', marker='+')\n",
    "    plt.scatter(times[indices_3], z_vel_error[indices_3], s=70, c='m', marker='*')\n",
    "    #plt.scatter(times, z_vel_error)\n",
    "    plt.ylabel('meters/second', fontsize=18)\n",
    "    plt.xlabel('Time (hours)', fontsize=18)\n",
    "    plt.legend(legend_names, fontsize=16)\n",
    "    plt.title('UKF Z Velocity Estimation Covariance Envelope', fontsize=18)\n",
    "    #plt.ylim([-z_range,z_range])\n",
    "    #plt.xlim([0,time_hrs[-1]])\n",
    "    plt.show()\n",
    "    #fig.savefig('z_vel_error.png')\n",
    "    \n",
    "    \n",
    "    print('Velocity RMS:')\n",
    "    error_x_vel_rms_3D = np.sqrt(np.mean(np.square(x_vel_error)))\n",
    "    print('X =', error_x_vel_rms_3D, 'meters/second')\n",
    "    \n",
    "    error_y_vel_rms_3D = np.sqrt(np.mean(np.square(y_vel_error)))\n",
    "    print('Y =', error_y_vel_rms_3D, 'meters/second')\n",
    "    \n",
    "    error_z_vel_rms_3D = np.sqrt(np.mean(np.square(z_vel_error)))\n",
    "    print('Z =', error_z_vel_rms_3D, 'meters/second')\n",
    "    \n",
    "    vel_rms = np.sqrt(error_x_vel_rms_3D**2 + error_y_vel_rms_3D**2 + error_z_vel_rms_3D**2)\n",
    "    print('Overall =', vel_rms/1e3, 'km/s')\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    fig.savefig('x_pos_error.png')\n",
    "    fig.savefig('y_pos_error.png')\n",
    "    fig.savefig('z_pos_error.png')\n",
    "    fig.savefig('x_vel_error.png')\n",
    "    fig.savefig('y_vel_error.png')\n",
    "    fig.savefig('z_vel_error.png')\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
